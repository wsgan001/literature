% Encoding: UTF-8

@Article{Viega2000,
  author        = {Viega, John and Bloch, J T and Kohno, Y and McGraw, Gary},
  title         = {{{\{}ITS4:{\}} {\{}A{\}} Static Vulnerability Scanner for {\{}C{\}} and {\{}C++{\}} Code}},
  journal       = {Acsac},
  year          = {2000},
  pages         = {257},
  __markedentry = {[ccc:3]},
  file          = {:article\\ITS4  A Static Vulnerability Scanner for C and C++ Code.pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, fuzz, second select, source code, source code-important, stat, static analysi, static analysis, survey, web, rank3},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,survey,web},
}

@Article{Wagner2000,
  author        = {Wagner, D and Foster, J S and Brewer, E a and Aiken, a},
  title         = {{A first step towards automated detection of buffer overrun vulnerabilities}},
  journal       = {Network and Distributed System Security Symposium},
  year          = {2000},
  pages         = {3--17},
  __markedentry = {[ccc:3]},
  abstract      = {We describe a new technique for finding potential buffer overrun vulnerabilities in security-critical C code. The key to success is to use static analysis: we formulate detection of buffer overruns as an integer range analysis problem. One major advantage of static analysis is that security bugs can be eliminated before code is deployed. We have implemented our design and used our prototype to find new remotely-exploitable vulnerabilities in a large, widely deployed software package. An earlier hand audit missed these bugs.},
  doi           = {citeulike-article-id:514510},
  file          = {:article\\A first step towards automated detection of buffer overrun vulnerabilities.pdf:PDF},
  groups        = {imprortant},
  isbn          = {189156207X,},
  keywords      = {first select, predicte, second select, source code, source code-important, stat, static analysi, static analysis, rank3},
  mendeley-tags = {first select,predicte,second select,source code,source code-important},
}

@Article{Larochelle2001a,
  author        = {Larochelle, David and Evans, David},
  title         = {{Statically Detecting Likely Buffer Overflow Vulnerabilities}},
  journal       = {Science},
  year          = {2001},
  volume        = {10},
  pages         = {177--190},
  __markedentry = {[ccc:2]},
  abstract      = {Buffer overflow attacks may be today's single most important security threat. This paper presents a new approach to mitigating buffer overflow vulnerabilities by detecting likely vulnerabilities through an analysis of the program source code. Our approach exploits information provided in semantic comments and uses lightweight and efficient static analyses. This paper describes an implementation of our approach that extends the LCLint annotation-assisted static checking tool. Our tool is as fast as a compiler and nearly as easy to use. We present experience using our approach to detect buffer overflow vulnerabilities in two security-sensitive programs.},
  file          = {:article\\Statically Detecting Likely Buffer Overflow Vulnerabilities.pdf:pdf},
  groups        = {imprortant},
  keywords      = {binary, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank2},
  mendeley-tags = {binary,first select,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://portal.acm.org/citation.cfm?id=1267612.1267626},
}

@Article{Shankar2001,
  author        = {Shankar, U and Talwar, K and Foster, J and Wagner, D},
  title         = {{Detecting Format-String Vulnerabilities with Type Qualifiers}},
  journal       = {Proceedings of the 10th USENIX Security Symposium},
  year          = {2001},
  __markedentry = {[ccc:5]},
  file          = {:article\\Detecting Format String Vulnerabilities with Type Qualifiers..pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Engler2001,
  author        = {Engler, Dawson and Chen, David Yu and Hallem, Seth and Chou, Andy and Chelf, Benjamin},
  title         = {{Bugs as deviant behavior: a general approach to inferring errors in systems code}},
  journal       = {ACM SIGOPS Operating Systems Review},
  year          = {2001},
  pages         = {57--72},
  __markedentry = {[ccc:5]},
  abstract      = {A major obstacle to finding program errors in a real sys- tem is knowing what correctness rules the system must obey. These rules are often undocumented or specified in an ad hoc manner. This paper demonstrates tech- niques that automatically extract such checking infor- mation from the source code itself, rather than the pro- grammer, thereby avoiding the need for a priori knowl- edge of system rules. The cornerstone of our approach is inferring pro- grammer "beliefs" that we then cross-check for contra- dictions. Beliefs are facts implied by code: a dereference of a pointer, p, implies a belief that p is non-null, a call to "tmlock(1)" implies that 1 was locked, etc. For be- liefs we know the programmer must hold, such as the pointer dereference above, we immediately flag contra- dictions as errors. For beliefs that the programmer may hold, we can assume these beliefs hold and use a sta- tistical analysis to rank the resulting errors from most to least likely. For example, a call to "spinlock" fol- lowed once by a call to "spintmlock" implies that the programmer may have paired these calls by coincidence. If the pairing happens 999 out of 1000 times, though, then it is probably a valid belief and the sole deviation a probable error. The key feature of this approach is that it requires no a priori knowledge of truth: if two beliefs contradict, we know that one is an error without knowing what the correct belief is. Conceptually, our checkers extract beliefs by tailor- ing rule "templates" to a system - for example, finding all functions that fit the rule template " must be paired with ." We have developed six checkers that follow this conceptual framework. They find hundreds of bugs in real systems such as Linux and OpenBSD. From our experience, they give a dramatic reduction in the manual effort needed to check a large system. Com- pared to our previous work 9, these template checkers find ten to one hundred times more rule instances and derive properties we found impractical to specify manually.},
  doi           = {10.1145/502034.502041},
  file          = {:article\\Bugs as Deviant Behavior  A General Approach.pdf:PDF},
  groups        = {imprortant},
  isbn          = {1581133898},
  issn          = {01635980},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://portal.acm.org/citation.cfm?id=502041},
}

@Article{Visser2002,
  author        = {Visser, Willem},
  title         = {{[22] Model Checking Programs}},
  journal       = {Automated Software Engineering},
  year          = {2002},
  pages         = {1--36},
  __markedentry = {[ccc:5]},
  file          = {:article\\Model Checking Programs.pdf:PDF},
  groups        = {imprortant},
  keywords      = {abstraction, binary, first select, java, model checking, runtime analysis, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, symmetry, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
}

@Article{Chen2002,
  author        = {Chen, Hao and Wagner, David},
  title         = {{MOPS: an Infrastructure for Examining Security Properties of Software}},
  journal       = {CCS '02: Proceedings of the 9th ACM Conference on Computer and Communications Security},
  year          = {2002},
  pages         = {235--244},
  __markedentry = {[ccc:5]},
  abstract      = {We describe a formal approach for finding bugs in security-relevant software and verifying their absence. The idea is as follows: we identify rules of safe programming practice, encode them as safety properties, and verify whether these properties are},
  doi           = {10.1145/586110.586142},
  file          = {:article\\MOPS an Infrastructure for Examining Security Properties of Software.pdf:pdf},
  groups        = {imprortant},
  isbn          = {1-58113-612-9},
  keywords      = {first select, model checking, second select, security, source code, source code-important, source code-vice important, stat, static analysi, static analysis, verification, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://portal.acm.org/citation.cfm?id=586110.586142},
}

@Article{Khurshid2003,
  author        = {Khurshid, Sarfraz and PĂsĂreanu, Corina S. and Visser, Willem},
  title         = {{Generalized Symbolic Execution for Model Checking and Testing}},
  journal       = {Tools and Algorithms for the Construction and Analysis of Systems},
  year          = {2003},
  volume        = {2619},
  pages         = {553--568},
  __markedentry = {[ccc:5]},
  abstract      = {Modern software systems, which often are concurrent and manipulate complex data structures must be extremely reliable. We present a novel framework based on symbolic execution, for automated checking of such systems. We provide a two-fold generalization of traditional symbolic execution based approaches. First, we define a source to source translation to instrument a program, which enables standard model checkers to perform symbolic execution of the program. Second, we give a novel symbolic execution algorithm that handles dynamically allocated structures (e.g., lists and trees), method preconditions (e.g., acyclicity), data (e.g., integers and strings) and concurrency. The program instrumentation enables a model checker to automatically explore different program heap configurations and manipulate logical formulae on program data (using a decision procedure). We illustrate two applications of our framework: checking correctness of multi-threaded programs that take inputs from unbounded domains with complex structure and generation of non-isomorphic test inputs that satisfy a testing criterion. Our implementation for Java uses the Java PathFinder model checker.},
  doi           = {10.1007/3-540-36577-X_40},
  file          = {:article\\Generalized Symbolic Execution for Model Checking and Testing.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9783540008989},
  issn          = {03029743},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://link.springer.com/10.1007/3-540-36577-X{\_}40},
}

@Article{Chess2004,
  author        = {Chess, B and McGraw, G},
  title         = {{Static analysis for security}},
  journal       = {Security $\backslash${\&} Privacy, IEEE},
  year          = {2004},
  volume        = {2},
  number        = {6},
  pages         = {76--79},
  __markedentry = {[ccc:1]},
  abstract      = {All software projects are guaranteed to have one artifact in common$\backslash$nsource code. Together with architectural risk analysis, code review$\backslash$nfor security ranks very high on the list of software security best$\backslash$npractices. We look at how to automate source-code security analysis$\backslash$nwith static analysis tools.},
  doi           = {10.1109/MSP.2004.111},
  file          = {:article\\Static analysis for security.pdf:pdf},
  groups        = {imprortant},
  isbn          = {1540-7993 VO  - 2},
  issn          = {1540-7993},
  keywords      = {first select,program diagnostics security of data software tool,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,survey},
}

@Article{Johnson2004,
  author        = {Johnson, Rob and Wagner, David},
  title         = {{Finding User / Kernel Pointer Bugs With Type Inference}},
  journal       = {13th USENIX Security Symposium},
  year          = {2004},
  __markedentry = {[ccc:5]},
  file          = {:article\\Finding User Kernel Pointer Bugs With Type Inference.pdf:pdf},
  groups        = {imprortant},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Huang2004,
  author        = {Huang, Yao-Wen and Yu, Fang and Hang, Christian and Tsai, Chung-Hung and Lee, Der-Tsai and Kuo, Sy-Yen},
  title         = {{Securing web application code by static analysis and runtime protection}},
  journal       = {Proceedings of the 13th international conference on World Wide Web},
  year          = {2004},
  pages         = {40--52},
  __markedentry = {[ccc:6]},
  abstract      = {Security remains a major roadblock to universal acceptance of the Web for many kinds of transactions, especially since the recent sharp increase in remotely exploitable vulnerabilities have been attributed to Web application bugs. Many verification tools are discovering previously unknown vulnerabilities in legacy C programs, raising hopes that the same success can be achieved with Web applications. In this paper, we describe a sound and holistic approach to ensuring Web application security. Viewing Web application vulnerabilities as a secure information flow problem, we created a lattice-based static analysis algorithm derived from type systems and typestate, and addressed its soundness. During the analysis, sections of code considered vulnerable are instrumented with runtime guards, thus securing Web applications in the absence of user intervention. With sufficient annotations, runtime overhead can be reduced to zero. We also created a tool named.WebSSARI (Web application Security by Static Analysis and Runtime Inspection) to test our algorithm, and used it to verify 230 open-source Web application projects on SourceForge.net, which were selected to represent projects of different maturity, popularity, and scale. 69 contained vulnerabilities. After notifying the developers, 38 acknowledged our findings and stated their plans to provide patches. Our statistics also show that static analysis reduced potential runtime overhead by 98.4{\%}.},
  doi           = {10.1145/988672.988679},
  file          = {:article\\Securing web application code by static analysis and runtime protection.pdf:pdf},
  groups        = {vice-important},
  isbn          = {1-58113-844-X},
  keywords      = {binary,first select,information flow,noninterference,predicte,program security,second select,security vulnerabilities,source code,source code-important,source code-vice important,stat,static analysi,static analysis,type systems,verification,web,web application security},
  mendeley-tags = {binary,first select,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://doi.acm.org/10.1145/988672.988679},
}

@Article{Visser2004,
  author        = {Visser, Willem and Pasareanu, Corina S. and Khurshid, Sarfraz},
  title         = {{Test Input Generation with Java PathFinder}},
  journal       = {ACM SIGSOFT Software Engineering Notes},
  year          = {2004},
  volume        = {29},
  number        = {4},
  pages         = {97},
  __markedentry = {[ccc:6]},
  abstract      = {We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures. We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java TreeMap library, using the Java PathFinder model checker. Three different test generation techniques will be introduced and compared, namely, straight model checking of the code, model checking used in a black-box fashion to generate all inputs up to a fixed size, and lastly, model checking used during white-box test input generation. The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data, taking into account complex method preconditions.},
  annote        = {模型检测和符号执行的应用},
  doi           = {10.1145/1013886.1007526},
  file          = {:article\\Test input generation with Java PathFinder.JPF-issta04.pdf:PDF},
  groups        = {, vice-important},
  isbn          = {1581138202},
  issn          = {01635948},
  keywords      = {binary,coverage,first select,ing,model check-,red-black trees,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,symbolic execution,testing object-oriented programs},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
}

@Article{Larus2004,
  author        = {Larus, James R. and Ball, Thomas and Das, Manuvir and DeLine, Robert and F{\"{a}}hndrich, Manuel and Pincus, Jon and Rajamani, Sriram K. and Venkatapathy, Ramanathan},
  title         = {{Righting software}},
  journal       = {IEEE Software},
  year          = {2004},
  volume        = {21},
  number        = {3},
  pages         = {92--100},
  __markedentry = {[ccc:6]},
  abstract      = { What tools do we use to develop and debug software? Most of us rely on a full-screen editor to write code, a compiler to translate it, a source-level debugger to correct it, and a source-code control system to archive and share it. These tools originated in the 1970s, when the change from batch to interactive programming stimulated the development of innovative languages, tools, environments, and other utilities we take for granted. Microsoft Research has developed two generations of tools, some of which Microsoft developers already use to find and correct bugs. These correctness tools can improve software development by systematically detecting programming errors.},
  doi           = {10.1109/MS.2004.1293079},
  file          = {:article\\Righting software.pdf:pdf},
  groups        = {vice-important},
  issn          = {07407459},
  keywords      = {first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Livshits2005,
  author        = {Livshits, V Benjamin and Lam, Monica S},
  title         = {{Finding Security Vulnerabilities in Java Applications with Static Analysis}},
  journal       = {Architecture},
  year          = {2005},
  pages         = {18},
  __markedentry = {[ccc:]},
  abstract      = {This paper proposes a static analysis technique for detecting many recently discovered application vulnerabilities such as SQL injections, cross-site scripting, and HTTP splitting attacks. These vulnerabilities stem from unchecked input, which is widely recognized as the most common source of security vulnerabilities in Web applications. We propose a static analysis approach based on a scalable and precise points-to analysis. In our system, user-provided specifications of vulnerabilities are automatically translated into static analyzers. Our approach finds all vulnerabilities matching a specification in the statically analyzed code. Results of our static analysis are presented to the user for assessment in an auditing interface integrated within Eclipse, a popular Java development environment. Our static analysis found 29 security vulnerabilities in nine large, popular open-source applications, with two of the vulnerabilities residing in widely-used Java libraries. In fact, all but one application in our benchmark suite had at least one vulnerability. Context sensitivity, combined with improved object naming, proved instrumental in keeping the number of false positives low. Our approach yielded very few false positives in our experiments: in fact, only one of our benchmarks suffered from false alarms.},
  doi           = {10.1.1.132.3096},
  file          = {:article\\Finding Security  Vulnerabilities  in Java Applications  with Static Analysis.pdf:PDF},
  groups        = {vice-important},
  keywords      = {binary, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  pmid          = {7665465},
  url           = {http://portal.acm.org/citation.cfm?id=1251416},
}

@Article{Cadar2005,
  author        = {Cadar, Cristian and Engler, Dawson},
  title         = {{Execution Generated Test Cases : How to Make Systems Code Crash Itself}},
  journal       = {Symposium A Quarterly Journal In Modern Foreign Literatures},
  year          = {2005},
  pages         = {2--23},
  __markedentry = {[ccc:3]},
  abstract      = {Abstract. This paper presents a technique that uses code to automat- ically generate its own test cases at run-time by using a combination of symbolic and concrete (i.e., regular) execution. The input values to a program (or software component) provide the standard interface of any testing framework with the program it is testing, and generating input values that will explore all the interesting behavior in the tested pro- gram remains an important open problem in software testing research. Our approach works by turning the problem on its head: we lazily gener- ate, from within the program itself, the input values to the program (and values derived from input values) as needed. We applied the technique to real code and found numerous corner-case errors ranging from simple memory overflows and infinite loops to subtle issues in the interpretation of language standards.},
  annote        = {测试样本生成的研究},
  doi           = {http://dx.doi.org/10.1007/11537328},
  file          = {:article\\Execution Generated Test Cases-How to Make Systems Code Crash Itself10.1.1.79.6663.pdf:PDF},
  groups        = {imprortant},
  isbn          = {3540281959},
  issn          = {03029743},
  keywords      = {binary, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {http://www.springerlink.com/index/6H0RAJ6K9ARVKPY0.pdf},
}

@PhdThesis{Sotirov2005,
  author        = {Sotirov, AI},
  title         = {{Automatic vulnerability detection using static source code analysis}},
  year          = {2005},
  __markedentry = {[ccc:5]},
  abstract      = {We present a static source analysis technique for vulnerability detection in C programs. Our approach is based on a combination of taint analysis, a well known vulnerability detection method, and value range propagation, a technique previously used for compiler optimizations. We examine a sample set of vulnerabilities and develop a vulnerability classi- fication based on common source code patterns. We identify three common charac- teristics present in most software vulnerabilities: one, data is read from an untrusted source, two, untrusted data is insufficiently validated, and three, untrusted data is used in a potentially vulnerable function or a language construct. We develop a static source analysis that is able to identify execution paths with these three characteristics and report them as potential vulnerabilities. We present an efficient implementation of our approach as an extension to the GNU C Compiler. We discuss the benefits of integrating a vulnerability detection system in a compiler. Finally, we present experimental results indicating a high level of accuracy of our technique.},
  booktitle     = {Vasa},
  file          = {:article\\AUTOMATIC VULNERABILITY DETECTION USING STATIC CODE ANALYSIS.pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {http://medcontent.metapress.com/index/A65RM03P4874243N.pdf$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.9646{\&}rep=rep1{\&}type=pdf},
}

@Article{Godefroid2005,
  author        = {Godefroid, Patrice and Klarlund, Nils},
  title         = {{Software model checking: Searching for computations in the abstract or the concrete}},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2005},
  volume        = {3771 LNCS},
  pages         = {20--32},
  __markedentry = {[ccc:5]},
  abstract      = {Software Model Checking: Searching for Computations in the Abstract or the Concrete Patrice Godefroid 1 and Nils Klarlund 2'* 1 Bell Laboratories, Lucent Technologies 2 Google Abstract. We review and discuss the current},
  doi           = {10.1007/11589976_3},
  file          = {:article\\Software model checking Searching for computations in the abstract or the concrete.pdf:pdf},
  groups        = {imprortant},
  isbn          = {3540304924},
  issn          = {03029743},
  keywords      = {first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,survey},
}

@Article{Pan2006,
  author        = {Pan, Kai and Kim, Sunghun and Whitehead, E. J. Jr.},
  title         = {{Bug Classification Using Program Slicing Metrics}},
  journal       = {International Workshop on Source Code Analysis and Manipulation},
  year          = {2006},
  pages         = {31--42},
  __markedentry = {[ccc:6]},
  abstract      = {In this paper, we introduce 13 program slicing metrics for C language programs. These metrics use program slice information to measure the size, complexity, coupling, and cohesion properties of programs. Compared with traditional code metrics based on code statements or code structure, program slicing metrics involve measures for program behaviors. To evaluate the program slicing metrics, we compare them with the Understand for C++ suite of metrics, a set of widely-used traditional code metrics, in a series of bug classification experiments. We used the program slicing and the Understand for C++ metrics computed for 887 revisions of the Apache HTTP project and 76 revisions of the Latex2rtf project to classify source code files or functions as either buggy or bug-free. We then compared their classification prediction accuracy. Program slicing metrics have slightly better performance than the Understand for C++ metrics in classifying buggy/bug-free source code. Program slicing metrics have an overall 82.6{\%} (Apache) and 92{\%} (Latex2rtf) accuracy at the file level, better than the Understand for C++ metrics with an overall 80.4{\%} (Apache) and 88{\%} (Latex2rtf) accuracy. The experiments illustrate that the program slicing metrics have at least the same bug classification performance as the Understand for C++ metrics.},
  annote        = {和软件度量有关},
  doi           = {10.1109/SCAM.2006.6},
  file          = {:article\\Bug Classification Using Program Slicing Metrics.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0769523536},
  keywords      = {first select, machine learning, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank4},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4026853},
}

@Article{Kim2006,
  author        = {Kim, Sunghun and Zimmermann, Thomas and Pan, Kai and {Jr. Whitehead}, E.},
  title         = {{Automatic Identification of Bug-Introducing Changes}},
  journal       = {21st IEEE/ACM International Conference on Automated Software Engineering (ASE'06)},
  year          = {2006},
  pages         = {81--90},
  __markedentry = {[ccc:2]},
  doi           = {10.1109/ASE.2006.23},
  file          = {:article\\Automatic Identification of Bug-Introducing Changes.pdf:pdf},
  groups        = {imprortant},
  isbn          = {0-7695-2579-2},
  keywords      = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4019564},
}

@Article{Howard2006,
  author        = {Howard, Michael A.},
  title         = {{A process for performing security code reviews}},
  journal       = {IEEE Security and Privacy},
  year          = {2006},
  volume        = {4},
  number        = {4},
  pages         = {74--79},
  __markedentry = {[ccc:1]},
  abstract      = {No one really likes reviewing source code for security vulnerabilities; its slow, tedious, and mind-numbingly boring. Yet, code review is a critical component of shipping secure software to customers. Neglecting it isn't an option},
  annote        = {代码审查的经验，可以作为一线人员是怎么寻找安全问题了，如何去降低他们的工作量。},
  doi           = {10.1109/MSP.2006.84},
  file          = {:article\\A process for performing security code reviews.pdf:pdf},
  groups        = {imprortant},
  issn          = {15407993},
  keywords      = {first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Jovanovic2006,
  author        = {Jovanovic, Nenad and Kruegel, Christopher and Kirda, Engin},
  title         = {{Pixy : A Static Analysis Tool for Detecting Web Application Vulnerabilities ( Short Paper )}},
  journal       = {proceedings of the IEEE on Security and Privacy},
  year          = {2006},
  pages         = {258--263},
  __markedentry = {[ccc:]},
  abstract      = {The number and the importance of Web applications haveincreasedrapidlyoverthelastyears. Atthesametime, the quantity and impact of security vulnerabilities in such applications have grown as well. Since manual code re- viewsaretime-consuming,error-proneandcostly,theneed forautomatedsolutionshasbecomeevident. In this paper, we address the problem of vulnerable Web applications by means of static source code analysis. More precisely, we use ﬂow-sensitive, interprocedural and context-sensitive data ﬂow analysis to discover vulnerable pointsinaprogram. Inaddition,aliasandliteralanalysis are employed to improve the correctness and precision of theresults. Thepresentedconceptsaretargetedatthegen- eralclassoftaint-stylevulnerabilitiesandcanbeappliedto the detection of vulnerability types such as SQL injection, cross-sitescripting,orcommandinjection. Pixy, the open source prototype implementation of our concepts, is targeted at detecting cross-site scripting vul- nerabilitiesin PHP scripts. Using our tool, we discovered andreported15previouslyunknownvulnerabilitiesinthree web applications, and reconstructed 36 known vulnerabil- ities in three other web applications. The observed false positive rate is at around 50{\%} (i.e., one false positive for eachvulnerability)andtherefore,lowenoughtopermitef- fectivesecurityaudits},
  doi           = {10.1109/SP.2006.29},
  file          = {:article\\Pixy A static analysis tool for detecting web application vulnerabilities（CR 120）.pdf:PDF},
  groups        = {vice-important},
  isbn          = {0-7695-2574-1},
  keywords      = {binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Chen2006,
  author        = {Chen, Shuo and Jun, X. U. and Kalbarczyk, Zbigniew and Iyer, Ravishankar K.},
  title         = {{Security vulnerabilities: From analysis to detection and masking techniques}},
  journal       = {Proceedings of the IEEE},
  year          = {2006},
  volume        = {94},
  number        = {2},
  pages         = {407--418},
  __markedentry = {[ccc:5]},
  abstract      = {This paper presents a study that uses extensive analysis of real security vulnerabilities to drive the development of: 1) runtime techniques for detection/masking of security attacks and 2) formal source code analysis methods to enable identification and removal of potential security vulnerabilities. A finite-state machine (FSM) approach is employed to decompose programs into multiple ele- mentary activities, making it possible to extract simple predicates to be ensured for security. The FSM analysis pinpoints common characteristics among a broad range of security vulnerabilities: predictable memory layout, unprotected control data, and pointer taintedness.We propose memory layout randomization and control data randomization to mask the vulnerabilities at runtime. We also propose a static analysis approach to detect potential security vulnerabilities using the notion of pointer taintedness.},
  doi           = {10.1109/JPROC.2005.862473},
  file          = {:article\\Security Vulnerabilities_From Analysis to Dectection and Masking Techniques.pdf:PDF},
  groups        = {imprortant},
  isbn          = {0018-9219},
  issn          = {00189219},
  keywords      = {Protection, Randomization, Security attack, Vulnerability, binary, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Louridas2006,
  author        = {Louridas, P.},
  title         = {{Static code analysis}},
  journal       = {IEEE Software},
  year          = {2006},
  volume        = {23},
  number        = {4},
  pages         = {58--61},
  __markedentry = {[ccc:6]},
  abstract      = {Programmers usually employ static checkers, it checks our programs for errors without executing them, in a process called static code analysis. In this way, it works with a program that has an initial indication of correctness (because it compiles) and try to avoid well-known traps and pitfalls before measuring it against its specifications (when it's tested). We use FindBugs, a popular open source static code checker for Java. Static code checkers in Java come in two flavors: those that work directly on the program source code and those that work on the compiled bytecode. Although each code checker works in its own way, most share some basic traits. They read the program and construct some model of it, a kind of abstract representation that they can use for matching the error patterns they recognize. They also perform some kind of data-flow analysis, trying to infer the possible values that variables might have at certain points in the program. Data-flow analysis is especially important for vulnerability checking, an increasingly important area for code checkers},
  doi           = {10.1109/MS.2006.114},
  file          = {:article\\Static code analysis.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0769523544},
  issn          = {0740-7459},
  keywords      = {first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank2},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,web},
  pmid          = {17411999},
}

@Article{MunsonJ.C.aNikora2006,
  author        = {{Munson J.C.a Nikora}, A.P.b Sherif J.S.c d},
  title         = {{Software faults: A quantifiable definition}},
  journal       = {Advances in Engineering Software},
  year          = {2006},
  volume        = {37},
  number        = {5},
  pages         = {327--333},
  __markedentry = {[ccc:2]},
  abstract      = {An important aspect of developing models relating the number and type$\backslash$nof faults in a software system to a set of structural measurement$\backslash$nis defining what constitutes a fault. By definition, a fault is a$\backslash$nstructural imperfection in a software system that may lead to the$\backslash$nsystem's eventually failing. A measurable and precise definition$\backslash$nof what faults are makes it possible to accurately identify and count$\backslash$nthem, which in turn allows the formulation of models relating fault$\backslash$ncounts and types to other measurable attributes of a software system.$\backslash$nUnfortunately, the most widely used definitions are not measurable$\backslash$n- there is no guarantee that two different individuals looking at$\backslash$nthe same set of failure reports and the same set of fault definitions$\backslash$nwill count the same number of underlying faults. The incomplete and$\backslash$nambiguous nature of current fault definitions adds a noise component$\backslash$nto the inputs used in modeling fault content. If this noise component$\backslash$nis sufficiently large, any attempt to develop a fault model will$\backslash$nproduce invalid results. In this paper, we base our recognition and$\backslash$nenumeration of software faults on the grammar of the language of$\backslash$nthe software system. By tokenizing the differences between a version$\backslash$nof the system exhibiting a particular failure behavior, and the version$\backslash$nin which changes were made to eliminate that behavior, we are able$\backslash$nto unambiguously count the number of faults associated with that$\backslash$nfailure. With modern configuration management tools, the identification$\backslash$nand counting of software faults can be automated. {\textcopyright} 2005 Elsevier$\backslash$nLtd. All rights reserved.},
  doi           = {10.1016/j.advengsoft.2005.07.003},
  file          = {:article\\Software faults_A quantifiable definition.pdf:PDF},
  groups        = {imprortant},
  issn          = {09659978},
  keywords      = {defect detection, first select, machine learning, predicte, second select, software faults, software quality, source code, source code-important, source code-vice important, rank2},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://www.scopus.com/inward/record.url?eid=2-s2.0-31044454098{\&}partnerID=40{\&}md5=53aee69af1c895b9b76cfe9ab232213e},
}

@Misc{Ganapathy2007,
  author        = {Ganapathy, Vinod and King, David and Jaeger, Trent and Jha, Somesh},
  title         = {{Mining security-sensitive operations in legacy code using concept analysis}},
  year          = {2007},
  __markedentry = {[ccc:6]},
  abstract      = {This paper presents an approach to statically retrofit legacy servers with mechanisms for authorization policy enforcement. The approach is based upon the observation that security-sensitive operations performed by a server are characterized by idiomatic resource manipulations, called fingerprints. Candidate fingerprints are automatically mined by clustering resource manipulations using concept analysis. These fingerprints are then used to identify security-sensitive operations performed by the server. Case studies with three real-world servers show that the approach can be used to identify security-sensitive operations with a few hours of manual effort and modest domain knowledge.},
  annote        = {安全敏感操作，此处概念需仔细辨认},
  booktitle     = {Proceedings - International Conference on Software Engineering},
  doi           = {10.1109/ICSE.2007.54},
  file          = {:article\\-Mining trends and patterns of software vulnerabilities.pdf:PDF},
  groups        = {vice-important},
  isbn          = {0769528287},
  issn          = {02705257},
  keywords      = {first select,second select,security-sensitive operations,source code,source code-important,source code-vice important},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  pages         = {458--467},
}

@Article{Black2007,
  author        = {Black, Paul E.},
  title         = {{SAMATE and evaluating static analysis tools}},
  journal       = {Ada User Journal},
  year          = {2007},
  volume        = {28},
  number        = {3},
  pages         = {184--188},
  __markedentry = {[ccc:5]},
  file          = {:article\\SAMATE and evaluating static analysis tools.pdf:pdf},
  groups        = {imprortant},
  issn          = {13816551},
  keywords      = {Software assurance, Source code, Static analysis, Tool testing, binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Engler2007,
  author        = {Engler, Dawson and Dunbar, Daniel},
  title         = {{Under-constrained Execution: Making Automatic Code Destruction Easy and Scalable}},
  journal       = {Proceedings of the 2007 international symposium on Software testing and analysis},
  year          = {2007},
  volume        = {0},
  pages         = {1--4},
  __markedentry = {[ccc:5]},
  abstract      = {An abstract is not available.},
  annote        = {KLEE的原始想法，动静结合的分析方法。},
  doi           = {10.1145/1273463.1273464},
  file          = {:article\\Under-constrained Execution_ Making Automatic Code Destruction Easy and Scalable.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781595937346},
  keywords      = {bug finding, dynamic analysis, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, symbolic execution, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Udrea2008,
  author        = {Udrea, Octavian and Lumezanu, Cristian and Foster, Jeffrey S.},
  title         = {{Rule-based static analysis of network protocol implementations}},
  journal       = {Information and Computation},
  year          = {2008},
  volume        = {206},
  number        = {2-4},
  pages         = {130--157},
  __markedentry = {[ccc:3]},
  abstract      = {Today's software systems communicate over the Internet using standard protocols that have been heavily scrutinized, providing some assurance of resistance to malicious attacks and general robustness. However, the software that implements those protocols may still contain mistakes, and an incorrect implementation could lead to vulnerabilities even in the most well-understood protocol. The goal of this work is to close this gap by introducing a new technique for checking that a C implementation of a protocol matches its description in an RFC or similar standards document. We present a static (compile-time) source code analysis tool called Pistachio that checks C code against a rule-based specification of its behavior. Rules describe what should happen during each round of communication, and can be used to enforce constraints on ordering of operations and on data values. Our analysis is not guaranteed sound due to some heuristic approximations it makes, but has a low false negative rate in practice when compared to known bug reports. We have applied Pistachio to two different implementations of SSH2 and an implementation of RCP. Pistachio discovered a multitude of bugs, including security vulnerabilities, that we confirmed by hand and checked against each project's bug databases. ?? 2007 Elsevier Inc. All rights reserved.},
  doi           = {10.1016/j.ic.2007.05.007},
  file          = {:article\\Rule-based static analysis of network protocol implementations.pdf:pdf},
  groups        = {imprortant},
  issn          = {08905401},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank3},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Cadar2008,
  author        = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson R.},
  title         = {{KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs}},
  journal       = {Proceedings of the 8th USENIX conference on Operating systems design and implementation},
  year          = {2008},
  pages         = {209--224},
  __markedentry = {[ccc:5]},
  abstract      = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage - on average over 90{\%} per tool (median: over 94{\%}) - and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100{\%} coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
  annote        = {在中间的字节码上运行},
  doi           = {10.1.1.142.9494},
  file          = {:article\\KLEE Unassisted and Automatic Generation of High-Coverag Tests for Complex Systems Programs.2008-12-OSDI-KLEE.pdf:PDF},
  groups        = {imprortant},
  isbn          = {978-1-931971-65-2},
  issn          = {{\textless}null{\textgreater}},
  keywords      = {binary, first select, fuzz, second select, source code, source code-important, source code-vice important, web, rank5},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {http://portal.acm.org/citation.cfm?id=1855756},
}

@Article{Guo2009,
  author        = {Guo, Philip J and Engler, Dawson},
  title         = {{Linux Kernel Developer Responses to Static Analysis Bug Reports}},
  journal       = {Proceedings of the 2009 Conference on USENIX Annual Technical Conference},
  year          = {2009},
  pages         = {22},
  __markedentry = {[ccc:1]},
  abstract      = {We present a study of how Linux kernel developers respond to bug reports issued by a static analysis tool. We found that developers prefer to triage reports in younger, smaller, and more actively-maintained files (2), first address easy-to-fix bugs and defer difficult (but possibly critical) bugs (3), and triage bugs in batches rather than individually (4). Also, although automated tools cannot find many types of bugs, they can be effective at directing developers' attentions towards parts of the codebase that contain up to 3X more user-reported bugs (5). Our insights into developer attitudes towards static analysis tools allow us to make suggestions for improving their usability and effectiveness. We feel that it could be effective to run static analysis tools continuously while programming and before committing code, to rank reports so that those most likely to be triaged are shown to developers first, to show the easiest reports to new developers, to perform deeper analysis on more actively-maintained code, and to use reports as indirect indicators of code quality and importance.},
  annote        = {有意思的研究点，linux内核开发者对待bug报告的反应。},
  file          = {:article\\Linux Kernel Developer Responses to Static Analysis Bug Reports.pdf:pdf},
  groups        = {imprortant},
  keywords      = {binary, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank1},
  mendeley-tags = {binary,first select,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://dl.acm.org/citation.cfm?id=1855807.1855829},
}

@Article{Penta2009,
  author        = {Penta, Massimiliano Di and Cerulo, Luigi and Aversano, Lerina},
  title         = {{The life and death of statically detected vulnerabilities: An empirical study}},
  journal       = {Information and Software Technology},
  year          = {2009},
  volume        = {51},
  number        = {10},
  pages         = {1469--1484},
  __markedentry = {[ccc:6]},
  abstract      = {Vulnerable statements constitute a major problem for developers and maintainers of networking systems. Their presence can ease the success of security attacks, aimed at gaining unauthorized access to data and functionality, or at causing system crashes and data loss. Examples of attacks caused by source code vulnerabilities are buffer overflows, command injections, and cross-site scripting. This paper reports on an empirical study, conducted across three networking systems, aimed at observing the evolution and decay of vulnerabilities detected by three freely available static analysis tools. In particular, the study compares the decay of different kinds of vulnerabilities, characterizes the decay likelihood through probability density functions, and reports a quantitative and qualitative analysis of the reasons for vulnerability removals. The study is performed by using a framework that traces the evolution of source code fragments across subsequent commits. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
  annote        = {有意思的研究点，研究源码漏洞的产生到修补的生命期},
  doi           = {10.1016/j.infsof.2009.04.013},
  file          = {:article\\The life and death of statically detected vulnerabilities_An empirical study.pdf:PDF},
  groups        = {vice-important},
  isbn          = {0950-5849},
  issn          = {09505849},
  keywords      = {Empirical study,Mining software repositories,Software vulnerabilities,first select,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2009.04.013},
}

@Article{Thummalapenta2009,
  author        = {Thummalapenta, Suresh and Xie, Tao and Tillmann, Nikolai and Halleux, Jonathan De and Schulte, Wolfram},
  title         = {{MSeqGen: object-oriented unit-test generation via mining source code}},
  journal       = {Foundations of Software Engineering},
  year          = {2009},
  pages         = {193--202},
  __markedentry = {[ccc:3]},
  abstract      = {An objective of unit testing is to achieve high structural coverage of the code under test. Achieving high structural overage of object-oriented code requires desirable method-call sequences that create and mutate objects. These sequences help generate target object states such as argument or receiver object states (in short as target states) of a method under test. Automatic generation of sequences for achieving target states is often challenging due to a large search space of possible sequences. On the other hand, code bases using object types (such as receiver or argument object types) include sequences that can be used to assist automatic test-generation approaches in achieving target states. In this paper, we propose a novel approach, called MSeqGen, that mines code bases and extracts sequences related to receiver or argument object types of a method under test. Our approach uses these extracted sequences to enhance two state-of-the-art test-generation approaches: random testing and dynamic symbolic execution. We conduct two evaluations to show the effectiveness of our approach. Using sequences extracted by our approach, we show that a random testing approach achieves 8.7{\%} (with a maximum of 20.0{\%} for one namespace) higher branch coverage and a dynamic-symbolic-execution-based approach achieves 17.4{\%} (with a maximum of 22.5{\%} for one namespace) higher branch coverage than without using our approach. Such an improvement is significant as the branches that are not covered by these state-of-the-art approaches are generally quite difficult to cover.},
  doi           = {10.1145/1595696.1595725},
  file          = {:article\\MSeqGen=Object-oriented unit-test generation via mining source .codeesecfse09-mseqgen.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781605580012},
  keywords      = {first select,object-oriented testing,second select,sequence mining,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  url           = {http://portal.acm.org/citation.cfm?id=1595725},
}

@Article{Catal2009,
  author        = {Catal, Cagatay and Diri, Banu},
  title         = {{A systematic review of software fault prediction studies}},
  journal       = {Expert Systems with Applications},
  year          = {2009},
  volume        = {36},
  number        = {4},
  pages         = {7346--7354},
  __markedentry = {[ccc:6]},
  abstract      = {This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.eswa.2008.10.027},
  file          = {:article\\A systematic review of software fault prediction studies.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0957-4174},
  issn          = {09574174},
  keywords      = {Automated fault prediction models,Expert systems,Machine learning,Method-level metrics,Public datasets,binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey},
  publisher     = {Elsevier Ltd},
  url           = {http://dx.doi.org/10.1016/j.eswa.2008.10.027},
}

@PhdThesis{HZL2010,
  author        = {{Hai Zhou Ling}},
  title         = {{Towards the automation of vulnerability detection in source code}},
  year          = {2010},
  __markedentry = {[ccc:4]},
  abstract      = {Software vulnerability detection, which involves security property specification and veri- fication, is essential in assuring the software security. However, the process of vulnera- bility detection is labor-intensive, time-consuming and error-prone if done manually. In this thesis, we present a hybrid approach, which utilizes the power of static and dynamic analysis for performing vulnerability detection in a systematic way. The key contributions of this thesis are threefold. First, a vulnerability detection framework, which supports se- curity property specification, potential vulnerability detection, and dynamic verification, is proposed. Second, an investigation of test data generation for dynamic verification is conducted. Third, the concept of reducing security property verification to reachability is introduced. m},
  file          = {:article\\Towards the automation of vulnerability detection in source code.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9780494672457},
  keywords      = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  number        = {December 2009},
}

@Article{Saxena2010,
  author        = {Saxena, Prateek and Akhawe, Devdatta and Hanna, Steve and Mao, Feng and McCamant, Stephen and Song, Dawn},
  title         = {{A Symbolic Execution Framework for JavaScript}},
  journal       = {2010 IEEE Symposium on Security and Privacy},
  year          = {2010},
  pages         = {513--528},
  __markedentry = {[ccc:6]},
  doi           = {10.1109/SP.2010.38},
  file          = {:article\\A Symbolic Execution Framework for JavaScript.pdf:pdf},
  groups        = {vice-important},
  isbn          = {978-1-4244-6894-2},
  keywords      = {-web security,first select,fuzz,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,string decision,symbolic execution,web},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5504700},
}

@Article{Bishop2010,
  author        = {Bishop, Matt and Howard, Damien and Engle, Sophie and Whalen, Sean},
  title         = {{A Taxonomy of Buffer Overflow Preconditions}},
  journal       = {Security},
  year          = {2010},
  volume        = {9},
  number        = {July 2006},
  pages         = {1--18},
  __markedentry = {[ccc:6]},
  file          = {:article\\A Taxonomy of Buffer Overflow Preconditions.pdf:pdf},
  groups        = {vice-important},
  keywords      = {arrays,binary,buffer overflows,first select,index terms,machine learning,predicte,program verification,protection mechanisms,second select,security,security privacy,software,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,vulnerabilities,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey,web},
  url           = {http://www.cs.ucdavis.edu/research/tech-reports/2010/CSE-2010-1.pdf},
}

@Article{Jovanovic2010,
  author        = {Jovanovic, Nenad and Kruegel, Christopher and Kirda, Engin},
  title         = {{Static analysis for detecting taint-style vulnerabilities in web applications}},
  journal       = {Journal of Computer Security},
  year          = {2010},
  volume        = {18},
  number        = {5},
  pages         = {861--907},
  __markedentry = {[ccc:6]},
  abstract      = {The number and the importance of web applications have increased rapidly over the last years. At the same time, the quantity and impact of security vulnerabilities in such applications have grown as well. Since manual code reviews are time-consuming, error-prone and costly, the need for automated solutions has become evident. In this paper, we address the problem of vulnerable web applications by means of static source code analysis. More precisely, we use flow-sensitive, interprocedural and context-sensitive data flow analysis to discover vulnerable points in a program. In addition to the taint analysis at the core of our engine, we employ a precise alias analysis targeted at the unique reference semantics commonly found in scripting languages. Moreover, we enhance the quality and quantity of the generated vulnerability reports by em- ploying an iterative two-phase algorithm for fast and precise resolution of file inclusions. The presented concepts are targeted at the general class of taint-style vulnerabilities and can be easily applied to the de- tection of vulnerability types such as SQL injection, cross-site scripting (XSS), and command injection. We implemented the presented concepts in Pixy, a high-precision static analysis tool aimed at detecting cross-site scripting and SQL injection vulnerabilities in PHP programs. To demonstrate the effectiveness of our techniques, we analyzed a number of popular, open-source web applications and discovered hun- dreds of previously unknown vulnerabilities. Both the high analysis speed as well as the low number of generated false positives show that our techniques can be used for conducting effective security audits.},
  doi           = {10.3233/JCS-2009-0385},
  file          = {:article\\Static analysis for detecting taint-style vulnerabilities in web applications.pdf:pdf},
  groups        = {vice-important},
  issn          = {0926227X},
  keywords      = {PHP,Program analysis,SQL injection,alias analysis,binary,cross-site scripting,data flow analysis,first select,scripting languages security,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web,web application security},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Khalid2010,
  author        = {Khalid, Shamsul Kamal Ahmad and Zimmermann, Jacob and Corney, Diane and Fidge, Colin},
  title         = {{Automatic generation of assertions to detect potential security vulnerabilities in C programs that use union and pointer types}},
  journal       = {Proceedings - 2010 4th International Conference on Network and System Security, NSS 2010},
  year          = {2010},
  pages         = {351--356},
  __markedentry = {[ccc:3]},
  doi           = {10.1109/NSS.2010.63},
  file          = {:article\\Automatic Generation of Assertions to Detect Potential Security Vulnerabilities in C.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9780769541594},
  keywords      = {C,Polymorphic types,Program analysis,Runtime assertions,first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Geer2011,
  author        = {Geer, Daniel E.},
  title         = {{Correlation is not causation}},
  journal       = {IEEE Security and Privacy},
  year          = {2011},
  volume        = {9},
  number        = {2},
  pages         = {93--94},
  __markedentry = {[ccc:6]},
  abstract      = {Vulnerability reporting rates don't seem overtly predictive of data loss events. Alternate, perhaps complex, hypotheses are needed if there is to be any further argument that data loss has as a causal component the existence of software vulnerabilities in the aggregate. This installment of For Good Measure looks deep into the statistics behind vulnerability reporting.},
  doi           = {10.1109/MSP.2011.26},
  file          = {:article\\Correlation is not causation.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0090-0036 (Print)$\backslash$n0090-0036 (Linking)},
  issn          = {15407993},
  keywords      = {data loss,first select,predicte,privacy,second select,security,source code,source code-important,source code-vice important,vulnerabilities},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important},
  pmid          = {9585761},
}

@Article{Yamaguchi2011,
  author        = {Yamaguchi, Fabian and Lindner, Felix and Rieck, Konrad},
  title         = {{Vulnerability Extrapolation: Assisted Discovery of Vulnerabilities Using Machine Learning}},
  journal       = {Proceedings of the 5th USENIX Conference on Offensive Technologies},
  year          = {2011},
  pages         = {13},
  __markedentry = {[ccc:5]},
  abstract      = {Rigorous identiﬁcation of vulnerabilities in program code is a key to implementing and operating secure systems. Unfortunately, only some types of vulnerabilities can be detected automatically. While techniques from software testing can accelerate the search for security ﬂaws, in the general case discovery of vulnerabilities is a tedious process that requires signiﬁcant expertise and time. In this paper, we propose a method for assisted discovery of vulnerabilities in source code. Our method proceeds by embedding code in a vector space and automatically determining API usage patterns using machine learning. Starting from a known vulnerability, these patterns can be exploited to guide the auditing of code and to identify potentially vulnerable code with similar characteristics—a process we refer to as vulnerability extrapolation. We empirically demonstrate the capabilities of our method in different experiments. In a case study with the library FFmpeg, we are able to narrow the search for interesting code from 6,778 to 20 functions and discover two security ﬂaws, one being a known ﬂaw and the other constituting a zero-day vulnerability.},
  file          = {:article\\Vulnerability Extrapolation-Assisted Discovery of Vulnerabilities using Machine Learning2011-woot.pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, machine learning, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,machine learning,second select,source code,source code-important,source code-vice important},
  url           = {http://dl.acm.org/citation.cfm?id=2028052.2028065},
}

@Article{Li2011,
  author        = {Li, Guodong and Ghosh, Indradeep and Rajan, Sreeranga P.},
  title         = {{KLOVER: A symbolic execution and automatic test generation tool for C++ programs}},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2011},
  volume        = {6806 LNCS},
  pages         = {609--615},
  __markedentry = {[ccc:5]},
  abstract      = {We present the first symbolic execution and automatic test generation tool for C++ programs. First we describe our effort in extending an existing symbolic execution tool for C programs to handle C++ programs. We then show how we made this tool generic, efficient and usable to handle real-life industrial applications. Novel features include extended symbolic virtual machine, library optimization for C and C++, object-level execution and reasoning, interfacing with specific type of efficient solvers, and semi-automatic unit and component testing. This tool is being used to assist the validation and testing of industrial software as well as publicly available programs written using the C++ language.},
  annote        = {将其转换为llvm中间码，再处理},
  doi           = {10.1007/978-3-642-22110-1_49},
  file          = {:article\\KLOVER-A symbolic execution and automatic test generation tool for C++ programs.CAV11.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9783642221095},
  issn          = {03029743},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Hu2011,
  author        = {Hu, Jian Jim and Wen, Qiaoyan and Sui, Ai Fen},
  title         = {{An efficient code audit method for accurately detecting security vulnerabilities in source codes}},
  journal       = {International Conference on Communication Technology Proceedings, ICCT},
  year          = {2011},
  pages         = {698--702},
  __markedentry = {[ccc:4]},
  abstract      = {Currently code security audit/review or white-box security test is widely used to analyze the source codes and detect security vulnerabilities. In this paper we describe a more efficient code security audit method based on the reference tree with security properties which building on all manipulable entries in source codes. This method can The method in this invention can greatly reduce false positives and provides an efficient solution for automated secure auditing on source codes by only checking the exploitable security flows.},
  doi           = {10.1109/ICCT.2011.6157966},
  file          = {:article\\An efficient code audit method for accurately detecting security vulnerabilities in source codes.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781612843070},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Hall2011,
  author        = {Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
  title         = {{A Systematic Review of Fault Prediction Performance in Software Engineering}},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2011},
  volume        = {38},
  number        = {6},
  pages         = {1276--1304},
  __markedentry = {[ccc:6]},
  abstract      = {Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs and improve the quality of software. Objective: We investigate how the context of models, the independent variables used and the modelling techniques applied, influence the performance of fault prediction models. Method:We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesise the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modelling techniques such as Na{\"{i}}ve Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology and performance comprehensively.},
  doi           = {10.1109/TSE.2011.103},
  file          = {:article\\A Systematic Review of Fault Prediction Performance in Software Engineering.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9781612081656},
  issn          = {0098-5589},
  keywords      = {first select,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,survey,web},
}

@Article{Catal2011,
  author        = {Catal, Cagatay},
  title         = {{Software fault prediction: A literature review and current trends}},
  journal       = {Expert Systems with Applications},
  year          = {2011},
  volume        = {38},
  number        = {4},
  pages         = {4626--4636},
  __markedentry = {[ccc:6]},
  abstract      = {Software engineering discipline contains several prediction approaches such as test effort prediction, correction cost prediction, fault prediction, reusability prediction, security prediction, effort prediction, and quality prediction. However, most of these prediction approaches are still in preliminary phase and more research should be conducted to reach robust models. Software fault prediction is the most popular research area in these prediction approaches and recently several research centers started new projects on this area. In this study, we investigated 90 software fault prediction papers published between year 1990 and year 2009 and then we categorized these papers according to the publication year. This paper surveys the software engineering literature on software fault prediction and both machine learning based and statistical based approaches are included in this survey. Papers explained in this article reflect the outline of what was published so far, but naturally this is not a complete review of all the papers published so far. This paper will help researchers to investigate the previous studies from metrics, methods, datasets, performance evaluation metrics, and experimental results perspectives in an easy and effective manner. Furthermore, current trends are introduced and discussed. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.eswa.2010.10.024},
  file          = {:article\\Software fault prediction A literature review and current trends.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0878353259},
  issn          = {09574174},
  keywords      = {Automated fault prediction models,Expert systems,Machine learning,Software engineering,Software quality engineering,Statistical methods,binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey,web},
  publisher     = {Elsevier Ltd},
  url           = {http://dx.doi.org/10.1016/j.eswa.2010.10.024},
}

@Article{Yu2011,
  author        = {Yu, Fang and Alkhalaf, Muath and Bultan, Tevfik},
  title         = {{Patching vulnerabilities with sanitization synthesis}},
  journal       = {2011 33rd International Conference on Software Engineering (ICSE)},
  year          = {2011},
  pages         = {251--260},
  __markedentry = {[ccc:6]},
  abstract      = {We present automata-based static string analysis techniques that automatically generate sanitization statements for patching vulnerable web applications. Our approach consists of three phases: Given an attack pattern we first conduct a vulnerability analysis to identify if strings that match the attack pattern can reach the security-sensitive functions. Next, we compute vulnerability signatures that characterize all input strings that can exploit the discovered vulnerability. Given the vulnerability signatures, we then construct sanitization statements that 1) check if a given input matches the vulnerability signature and 2) modify the input in a minimal way so that the modified input does not match the vulnerability signature. Our approach is capable of generating relational vulnerability signatures (and corresponding sanitization statements) for vulnerabilities that are due to more than one input.},
  annote        = {the security-sensitive functions.},
  doi           = {10.1145/1985793.1985828},
  file          = {:article\\Patching vulnerabilities with sanitization synthesis.pdf:pdf},
  groups        = {vice-important},
  isbn          = {978-1-4503-0445-0},
  issn          = {0270-5257},
  keywords      = {automata,first select,sanitization synthesis,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,string analysis,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Schryen2011,
  author        = {Schryen, Guido},
  title         = {{Is open source security a myth?}},
  journal       = {Communications of the ACM},
  year          = {2011},
  volume        = {54},
  number        = {5},
  pages         = {130},
  __markedentry = {[ccc:6]},
  abstract      = {What does vulnerability and patch data say?},
  doi           = {10.1145/1941487.1941516},
  groups        = {imprortant},
  isbn          = {0001-0782},
  issn          = {00010782},
  keywords      = {binary,first select,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,predicte,second select,source code,source code-important,source code-vice important,web},
  pmid          = {60863987},
}

@Article{Shin2011,
  author        = {Shin, Yonghee and Meneely, Andrew and Williams, Laurie and Osborne, Jason A.},
  title         = {{Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities}},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2011},
  volume        = {37},
  number        = {6},
  pages         = {772--787},
  __markedentry = {[ccc:6]},
  abstract      = {Security inspection and testing require experts in security who think like an attacker. Security experts need to know code locations on which to focus their testing and inspection efforts. Since vulnerabilities are rare occurrences, locating vulnerable code locations can be a challenging task. We investigated whether software metrics obtained from source code and development history are discriminative and predictive of vulnerable code locations. If so, security experts can use this prediction to prioritize security inspection and testing efforts. The metrics we investigated fall into three categories: complexity, code churn, and developer activity metrics. We performed two empirical case studies on large, widely used open-source projects: the Mozilla Firefox web browser and the Red Hat Enterprise Linux kernel. The results indicate that 24 of the 28 metrics collected are discriminative of vulnerabilities for both projects. The models using all three types of metrics together predicted over 80 percent of the known vulnerable files with less than 25 percent false positives for both projects. Compared to a random selection of files for inspection and testing, these models would have reduced the number of files and the number of lines of code to inspect or test by over 71 and 28 percent, respectively, for both projects. 2006 IEEE.},
  doi           = {10.1109/TSE.2010.81},
  file          = {:article\\Evaluating complexity, code churn, developer activity metrics as indicators of software vulnerabilities-正式.pdf:PDF;:article\\Evaluating complexity, code churn, developer activity metrics as indicators of software vulnerabilities.pdf:PDF},
  groups        = {vice-important},
  isbn          = {2009030060},
  issn          = {00985589},
  keywords      = {Fault prediction,binary,first select,machine learning,predicte,second select,software metrics,software security,source code,source code-important,source code-vice important,stat,static analysi,static analysis,vulnerability prediction,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Johns2011,
  author        = {Johns, Martin},
  title         = {{Code-injection Vulnerabilities in Web Applications — Exemplified at Cross-site Scripting}},
  journal       = {it - Information Technology},
  year          = {2011},
  volume        = {53},
  number        = {5},
  pages         = {256--260},
  __markedentry = {[ccc:6]},
  doi           = {10.1524/itit.2011.0651},
  file          = {:article\\Code-injection Vulnerabilities in Web Applications — Exemplified at Cross-site Scripting.pdf:pdf},
  groups        = {vice-important},
  issn          = {1611-2776},
  keywords      = {2,3,4,code injection,d,first select,processors,programming languages,second select,security,software,software engineering,source code,source code-important,source code-vice important,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  url           = {http://www.degruyter.com/doi/10.1524/itit.2011.0651},
}

@Article{王雷2011,
  author        = {王雷},
  title         = {基于约束分析和模型检测的代码安全漏洞检测方法研究},
  journal       = {计算机研究与发展},
  year          = {2011},
  __markedentry = {[ccc:5]},
  file          = {:article\\基于约束分析与模型检测的代码安全漏洞检测方法研究.pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Bradley2012,
  author        = {Bradley, Mark and Cassez, Franck and Fehnker, Ansgar and Given-Wilson, Thomas and Huuck, Ralf},
  title         = {{High performance static analysis for industry}},
  journal       = {Electronic Notes in Theoretical Computer Science},
  year          = {2012},
  volume        = {289},
  pages         = {3--14},
  __markedentry = {[ccc:5]},
  abstract      = {Static source code analysis for software bug detection has come a long way since its early beginnings as a compiler technology. However, with the introduction of more sophisticated algorithmic techniques, such as model checking and constraint solving, questions about performance are a major concern. In this work we present an empirical study of our industrial strength source code analysis tool Goanna that uses a model checking core for static analysis of C/C++ code. We present the core technology and abstraction mechanism with a focus on performance, as guided by experience from having analyzed millions of lines of code. In particular, we present results from our recent study within the NIST/DHS SAMATE program. The results show that, maybe surprisingly, formal verification techniques can be used successfully in practical industry applications scaling roughly linearly, even for millions of lines of code. Crown Copyright ?? 2012 Published by Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.entcs.2012.11.002},
  file          = {:article\\High performance static analysis for industry.pdf:pdf},
  groups        = {imprortant},
  issn          = {15710661},
  keywords      = {C/C++, SAMATE, Validation, first select, model checking, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, tools, verification, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.entcs.2012.11.002},
}

@Article{Ding2012,
  author        = {Ding, Sun and Tan, Hee Beng Kuan and Liu, Kaiping and Chandramohan, Mahinthan and Zhang, Hongyu},
  title         = {{Detection of buffer overflow vulnerabilities in C/C++ with pattern based limited symbolic evaluation}},
  journal       = {Proceedings - International Computer Software and Applications Conference},
  year          = {2012},
  pages         = {559--564},
  __markedentry = {[ccc:5]},
  abstract      = {Buffer overflow vulnerability is one of the major security threats for applications written in C/C++. Among the existing approaches for detecting buffer overflow vulnerability, though flow sensitive based approaches offer higher precision but they are limited by heavy overhead and the fact that many constraints are unsolvable. We propose a novel method to efficiently detect vulnerable buffer overflows in any given control flow graph through recognizing two patterns. The proposed approach first uses syntax analysis to filter away those branches that cannot possibly comply with any of the two patterns before applying a limited symbolic evaluation for a precise matching against the patterns. The proposed approach only needs to evaluate a limited set of selected branch predicates according to the patterns and avoids the need to deal with a large number of general branch predicates. This significantly improves the scalability while not sacrificing the detection precision. Our experiments demonstrate the scalability and efficiency of the proposed method, which demonstrates its applicability.},
  doi           = {10.1109/COMPSACW.2012.103},
  file          = {:article\\Detection of Buffer Overflow Vulnerabilities in C C++ with Pattern based Limited Symbolic Evaluation.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9780769547589},
  issn          = {07303157},
  keywords      = {Empirical study, Pattern recognition, Security, Symbolic evaluation, Verification, binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
}

@Article{Yamaguchi2012,
  author        = {Yamaguchi, Fabian and Lottmann, Markus and Rieck, Konrad},
  title         = {{Generalized Vulnerability Extrapolation using Abstract Syntax Trees}},
  journal       = {ACSAC '12 Proceedings of the 28th Annual Computer Security Applications Conference},
  year          = {2012},
  pages         = {359--368},
  __markedentry = {[ccc:5]},
  abstract      = {The discovery of vulnerabilities in source code is a key for securing computer systems. While specific types of security flaws can be identified automatically, in the general case the process of finding vulnerabilities cannot be automated and vulnerabilities are mainly discovered by manual analysis. In this paper, we propose a method for assisting a security analyst during auditing of source code. Our method proceeds by extracting abstract syntax trees from the code and determining structural patterns in these trees, such that each function in the code can be described as a mixture of these patterns. This representation enables us to decompose a known vulnerability and extrapolate it to a code base, such that functions potentially suffering from the same flaw can be suggested to the analyst. We evaluate our method on the source code of four popular open-source projects: LibTIFF, FFmpeg, Pidgin and Asterisk. For three of these projects, we are able to identify zero-day vulnerabilities by inspecting only a small fraction of the code bases.},
  doi           = {10.1145/2420950.2421003},
  file          = {:article\\Generalized Vulnerability Extrapolation using  Abstract Syntactic Trees-2012-acsac（CR17）.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781450313124},
  issn          = {2229-6166},
  keywords      = {binary, first select, fuzz, machine learning, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,web},
}

@Article{Elberzhager2012,
  author        = {Elberzhager, Frank and Rosbach, Alla and M??nch, J??rgen and Eschbach, Robert},
  title         = {{Reducing test effort: A systematic mapping study on existing approaches}},
  journal       = {Information and Software Technology},
  year          = {2012},
  volume        = {54},
  number        = {10},
  pages         = {1092--1106},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Quality assurance effort, especially testing effort, is often a major cost factor during software development, which sometimes consumes more than 50{\%} of the overall development effort. Consequently, one major goal is often to reduce testing effort. Objective: The main goal of the systematic mapping study is the identification of existing approaches that are able to reduce testing effort. Therefore, an overview should be presented both for researchers and practitioners in order to identify, on the one hand, future research directions and, on the other hand, potential for improvements in practical environments. Method: Two researchers performed a systematic mapping study, focusing on four databases with an initial result set of 4020 articles. Results: In total, we selected and categorized 144 articles. Five different areas were identified that exploit different ways to reduce testing effort: approaches that predict defect-prone parts or defect content, automation, test input reduction approaches, quality assurance techniques applied before testing, and test strategy approaches. Conclusion: The results reflect an increased interest in this topic in recent years. A lot of different approaches have been developed, refined, and evaluated in different environments. The highest attention was found with respect to automation and prediction approaches. In addition, some input reduction approaches were found. However, in terms of combining early quality assurance activities with testing to reduce test effort, only a small number of approaches were found. Due to the continuous challenge of reducing test effort, future research in this area is expected. ?? 2012 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2012.04.007},
  file          = {:article\\Reducing test effort_A systematic mapping study on existing approaches.pdf:PDF},
  groups        = {vice-important},
  issn          = {09505849},
  keywords      = {Efficiency improvement,Mapping study,Quality assurance,Software testing,Test effort reduction,first select,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,survey,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2012.04.007},
}

@Article{Shar2012,
  author        = {Shar, Lwin Khin and Tan, Hee Beng Kuan},
  title         = {{Automated removal of cross site scripting vulnerabilities in web applications}},
  journal       = {Information and Software Technology},
  year          = {2012},
  volume        = {54},
  number        = {5},
  pages         = {467--478},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Cross site scripting (XSS) vulnerability is among the top web application vulnerabilities according to recent surveys. This vulnerability occurs when a web application uses inputs received from users in web pages without properly checking them. This allows an attacker to inject malicious scripts in web pages via such inputs such that the scripts perform malicious actions when a client visits the exploited web pages. Such an attack may cause serious security violations such as account hijacking and cookie theft. Current approaches to mitigate this problem mainly focus on effective detection of XSS vulnerabilities in the programs or prevention of real time XSS attacks. As more sophisticated attack vectors are being discovered, vulnerabilities if not removed could be exploited anytime. Objective: To address this issue, this paper presents an approach for removing XSS vulnerabilities in web applications. Method: Based on static analysis and pattern matching techniques, our approach identifies potential XSS vulnerabilities in program source code and secures them with appropriate escaping mechanisms which prevent input values from causing any script execution. Results: We developed a tool, saferXSS, to implement the proposed approach. Using the tool, we evaluated the applicability and effectiveness of the proposed approach based on the experiments on five Java-based web applications. Conclusion: Our evaluation has shown that the tool can be applied to real-world web applications and it automatically removed all the real XSS vulnerabilities in the test subjects. ?? 2011 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2011.12.006},
  file          = {:article\\Automated removal of cross site scripting vulnerabilities in web applications.pdf:pdf},
  groups        = {vice-important},
  isbn          = {0-7695-2224-6},
  issn          = {09505849},
  keywords      = {Automated bug fixing,Character escaping,Cross site scripting,Encoding,Injection vulnerability,Web security,binary,first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2011.12.006},
}

@Article{Shahmehri2012,
  author        = {Shahmehri, Nahid and Mammar, Amel and {Montes De Oca}, Edgardo and Byers, David and Cavalli, Ana and Ardi, Shanai and Jimenez, Willy},
  title         = {{An advanced approach for modeling and detecting software vulnerabilities}},
  journal       = {Information and Software Technology},
  year          = {2012},
  volume        = {54},
  number        = {9},
  pages         = {997--1013},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Passive testing is a technique in which traces collected from the execution of a system under test are examined for evidence of flaws in the system. Objective: In this paper we present a method for detecting the presence of security vulnerabilities by detecting evidence of their causes in execution traces. This is a new approach to security vulnerability detection. Method: Our method uses formal models of vulnerability causes, known as security goal models and vulnerability detection conditions (VDCs). The former are used to identify the causes of vulnerabilities and model their dependencies, and the latter to give a formal interpretation that is suitable for vulnerability detection using passive testing techniques. We have implemented modeling tools for security goal models and vulnerability detection conditions, as well as TestInv-Code, a tool that checks execution traces of compiled programs for evidence of VDCs. Results: We present the full definitions of security goal models and vulnerability detection conditions, as well as structured methods for creating both. We describe the design and implementation of TestInv-Code. Finally we show results obtained from running TestInv-Code to detect typical vulnerabilities in several open source projects. By testing versions with known vulnerabilities, we can quantify the effectiveness of the approach. Conclusion: Although the current implementation has some limitations, passive testing for vulnerability detection works well, and using models as the basis for testing ensures that users of the testing tool can easily extend it to handle new vulnerabilities. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2012.03.004},
  file          = {:article\\An advanced approach for modeling and detecting software vulnerabilities.pdf:pdf},
  groups        = {vice-important},
  issn          = {09505849},
  keywords      = {Automatic testing, Dynamic analysis, Secure software engineering, Security modelling, Software security, binary, first select, fuzz, machine learning, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2012.03.004},
}

@Article{Zhang2012b,
  author        = {Zhang, Ruoyu and Huang, Shiqiu and Qi, Zhengwei and Guan, Haibing},
  title         = {{Static program analysis assisted dynamic taint tracking for software vulnerability discovery}},
  journal       = {Computers and Mathematics with Applications},
  year          = {2012},
  volume        = {63},
  number        = {2},
  pages         = {469--480},
  __markedentry = {[ccc:5]},
  abstract      = {The evolution of computer science has exposed us to the growing gravity of security problems and threats. Dynamic taint analysis is a prevalent approach to protect a program from malicious behaviors, but fails to provide any information about the code which is not executed. This paper describes a novel approach to overcome the limitation of traditional dynamic taint analysis by integrating static analysis into the system and presents framework SDCF to detect software vulnerabilities with high code coverage. Our experiments show that SDCF is not only able to provide efficient runtime protection by introducing an overhead of 4.16× based on the taint tracing technique, but is also capable of discovering latent software vulnerabilities which have not been exploited, and achieve code coverage of more than 90{\%}. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.camwa.2011.08.001},
  file          = {:article\\Static program analysis assisted dynamic taint tracking for software vulnerability discovery.pdf:pdf},
  groups        = {imprortant},
  issn          = {08981221},
  keywords      = {Code coverage, Data flow analysis, Software vulnerability, Taint analysis, binary, first select, fuzz, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,predicte,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier Ltd},
  url           = {http://dx.doi.org/10.1016/j.camwa.2011.08.001},
}

@Article{Li2013,
  author        = {Li, Hongzhe and Kim, Taebeom and Bat-Erdene, Munkhbayar and Lee, Heejo},
  title         = {{Software vulnerability detection using backward trace analysis and symbolic execution}},
  journal       = {Proceedings - 2013 International Conference on Availability, Reliability and Security, ARES 2013},
  year          = {2013},
  pages         = {446--454},
  __markedentry = {[ccc:5]},
  abstract      = {Software vulnerability has long been considered an important threat to the safety of software systems. When source code is accessible, we can get much help from the information of source code to detect vulnerabilities. Static analysis has been used frequently to scan code for errors that cause security problems when source code is available. However, they often generate many false positives. Symbolic execution has also been proposed to detect vulnerabilities and has shown good performance in some researches. However, they are either ineffective in path exploration or could not scale well to large programs. During practical use, since most of paths are actually not related to security problems and software vulnerabilities are usually caused by the improper use of security-sensitive functions, the number of paths could be reduced by tracing sensitive data backwardly from security-sensitive functions so as to consider paths related to vulnerabilities only. What's more, in order to leave ourselves free from generating bug triggering test input, formal reasoning could be used by solving certain program conditions. In this research, we propose backward trace analysis and symbolic execution to detect vulnerabilities from source code. We first find out all the hot spot in source code file. Based on each hot spot, we construct a data flow tree so that we can get the possible execution traces. Afterwards, we do symbolic execution to generate program constraint(PC) and get security constraint(SC) from our predefined security requirements along each execution trace. A program constraint is a constraint imposed by program logic on program variables. A security constraint(SC) is a constraint on program variables that must be satisfied to ensure system security. Finally, this hot spot will be reported as a vulnerability if there is an assignment of values to program inputs which could satisfy PC but violates SC, in other words, satisfy PC $\Lambda$ S̅C̅. We have - mplemented our approach and conducted experiments on test cases which we randomly choose from Juliet Test Suites provided by US National Security Agency(NSA). The results show that our approach achieves Precision value of 83.33{\%}, Recall value of 90.90{\%} and F1 Value of 86.95{\%} which gains the best performance among competing tools. Moreover, our approach can efficiently mitigate path explosion problem in traditional symbolic execution.},
  annote        = {将符号执行用在源码上，精读},
  doi           = {10.1109/ARES.2013.59},
  file          = {:article\\Software vulnerability detection using backward trace analysis and symbolic execution.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9780769550084},
  keywords      = {Program constraint, Static analysis, Symbolic execution, Vulnerability detection, binary, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important},
}

@Article{王雅文2013,
  author        = {王雅文},
  title         = {一种基于代码静态分析的缓冲区溢出检测算法},
  journal       = {Journal of Chemical Information and Modeling},
  year          = {2013},
  volume        = {53},
  number        = {9},
  pages         = {1689--1699},
  __markedentry = {[ccc:5]},
  abstract      = {applicability for this approach.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1011.1669v3},
  doi           = {10.1017/CBO9781107415324.004},
  eprint        = {arXiv:1011.1669v3},
  file          = {:article\\一种基于代码静态分析的缓冲区溢出检测算法.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9788578110796},
  issn          = {1098-6596},
  keywords      = {first select, icle, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  pmid          = {25246403},
}

@Article{Davidson2013,
  author        = {Davidson, Drew and Moench, Benjamin and Jha, Somesh and Ristenpart, Thomas},
  title         = {{FIE on Firmware: Finding Vulnerabilities in Embedded Systems using Symbolic Execution}},
  journal       = {Proceedings of the 22nd USENIX Security Symposium},
  year          = {2013},
  pages         = {463--478},
  __markedentry = {[ccc:6]},
  file          = {:article\\FIE on Firmware Finding Vulnerabilities in Embedded Systems using Symbolic Execution.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9781931971034},
  keywords      = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/davidson},
}

@Article{Radjenovic2013,
  author        = {Radjenovi{\'{c}}, Danijel and Heri{\v{c}}ko, Marjan and Torkar, Richard and {\v{Z}}ivkovi{\v{c}}, Ale{\v{s}}},
  title         = {{Software fault prediction metrics: A systematic literature review}},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {8},
  pages         = {1397--1418},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Software metrics may be used in fault prediction models to improve software quality by predicting fault location. Objective: This paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. Method: This systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. Results: Object-oriented metrics (49{\%}) were used nearly twice as often compared to traditional source code metrics (27{\%}) or process metrics (24{\%}). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. Conclusion: More studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2013.02.009},
  file          = {:article\\Software fault prediction metrics A systematic literature review.pdf:pdf},
  groups        = {vice-important},
  isbn          = {09505849},
  issn          = {09505849},
  keywords      = {Software fault prediction,Software metric,Systematic literature review,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey,web},
}

@Article{Yamaguchi2013,
  author        = {Yamaguchi, Fabian and Wressnegger, Christian and Gascon, Hugo and Rieck, Konrad},
  title         = {{Chucky: Exposing Misssing Checks in Source Code for Vulnerability Discovery}},
  journal       = {Proceedings of the 2013 ACM SIGSAC conference on Computer {\&} communications security - CCS '13},
  year          = {2013},
  number        = {October 2015},
  pages         = {499--510},
  __markedentry = {[ccc:5]},
  doi           = {10.1145/2508859.2516665},
  file          = {:article\\Chucky- Exposing missing checks in source code for Vulnerability Discovery（CR 12）.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781450324779},
  keywords      = {anomaly detection, binary, first select, fuzz, machine learning, second select, source code, source code-important, stat, static analysi, static analysis, vulnerabilities, web, rank5},
  mendeley-tags = {binary,first select,fuzz,machine learning,second select,source code,source code-important,web},
  url           = {http://dl.acm.org/citation.cfm?doid=2508859.2516665},
}

@Article{Garousi2013,
  author        = {Garousi, Vahid and Mesbah, Ali and Betin-Can, Aysu and Mirshokraie, Shabnam},
  title         = {{A systematic mapping study of web application testing}},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {8},
  pages         = {1374--1396},
  __markedentry = {[ccc:6]},
  abstract      = {Context: The Web has had a significant impact on all aspects of our society. As our society relies more and more on the Web, the dependability of web applications has become increasingly important. To make these applications more dependable, for the past decade researchers have proposed various techniques for testing web-based software applications. Our literature search for related studies retrieved 147 papers in the area of web application testing, which have appeared between 2000 and 2011. Objective As this research area matures and the number of related papers increases, it is important to systematically identify, analyze, and classify the publications and provide an overview of the trends in this specialized field. Method We review and structure the body of knowledge related to web application testing through a systematic mapping (SM) study. As part of this study, we pose two sets of research questions, define selection and exclusion criteria, and systematically develop and refine a classification schema. In addition, we conduct a bibliometrics analysis of the papers included in our study. Results Our study includes a set of 79 papers (from the 147 retrieved papers) published in the area of web application testing between 2000 and 2011. We present the results of our systematic mapping study. Our mapping data is available through a publicly-accessible repository. We derive the observed trends, for instance, in terms of types of papers, sources of information to derive test cases, and types of evaluations used in papers. We also report the demographics and bibliometrics trends in this domain, including top-cited papers, active countries and researchers, and top venues in this research area. Conclusion We discuss the emerging trends in web application testing, and discuss the implications for researchers and practitioners in this area. The results of our systematic mapping can help researchers to obtain an overview of existing web application testing approaches and indentify areas in the field that require more attention from the research community. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2013.02.006},
  file          = {:article\\A systematic mapping study of web application testing.pdf:pdf},
  groups        = {vice-important},
  issn          = {09505849},
  keywords      = {Bibliometrics,Paper repository,Systematic mapping,Testing,Web application,first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,survey,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2013.02.006},
}

@Article{Diaz2013,
  author        = {D{\'{i}}az, Gabriel and Bermejo, Juan Ram{\'{o}}n},
  title         = {{Static analysis of source code security: Assessment of tools against SAMATE tests}},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {8},
  pages         = {1462--1476},
  __markedentry = {[ccc:3]},
  abstract      = {Context: Static analysis tools are used to discover security vulnerabilities in source code. They suffer from false negatives and false positives. A false positive is a reported vulnerability in a program that is not really a security problem. A false negative is a vulnerability in the code which is not detected by the tool. Objective: The main goal of this article is to provide objective assessment results following a well-defined and repeatable methodology that analyzes the performance detecting security vulnerabilities of static analysis tools. The study compares the performance of nine tools (CBMC, K8-Insight, PC-lint, Prevent, Satabs, SCA, Goanna, Cx-enterprise, Codesonar), most of them commercials tools, having a different design. Method: We executed the static analysis tools against SAMATE Reference Dataset test suites 45 and 46 for C language. One includes test cases with known vulnerabilities and the other one is designed with specific vulnerabilities fixed. Afterwards, the results are analyzed by using a set of well known metrics. Results: Only SCA is designed to detect all vulnerabilities considered in SAMATE. None of the tools detect "cross-site scripting" vulnerabilities. The best results for F-measure metric are obtained by Prevent, SCA and K8-Insight. The average precision for analyzed tools is 0.7 and the average recall is 0.527. The differences between all tools are relevant, detecting different kinds of vulnerabilities. Conclusions: The results provide empirical evidences that support popular propositions not objectively demonstrated until now. The methodology is repeatable and allows ranking strictly the analyzed static analysis tools, in terms of vulnerabilities coverage and effectiveness for detecting the highest number of vulnerabilities having few false positives. Its use can help practitioners to select appropriate tools for a security review process of code. We propose some recommendations for improving the reliability and usefulness of static analysis tools and the process of benchmarking. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2013.02.005},
  file          = {:article\\Static analysis of source code security_Assessment of tools against SAMATE tests.pdf:PDF},
  groups        = {imprortant},
  issn          = {09505849},
  keywords      = {Quality analysis and evaluation, Security development lifecycle, Security tools, Software/program verification, Vulnerability, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank3},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2013.02.005},
}

@Article{Zhu2013,
  author        = {Zhu, Haiyan and Dillig, Thomas and Dillig, Isil},
  title         = {{Automated inference of library specifications for source-sink property verification}},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2013},
  volume        = {8301 LNCS},
  pages         = {290--306},
  __markedentry = {[ccc:6]},
  doi           = {10.1007/978-3-319-03542-0_21},
  file          = {:article\\Automated Inference of Library Specifications for source-sink.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9783319035413},
  issn          = {03029743},
  keywords      = {binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Austin2013,
  author        = {Austin, Andrew and Holmgreen, Casper and Williams, Laurie},
  title         = {{A comparison of the efficiency and effectiveness of vulnerability discovery techniques}},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {7},
  pages         = {1279--1288},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Security vulnerabilities discovered later in the development cycle are more expensive to fix than those discovered early. Therefore, software developers should strive to discover vulnerabilities as early as possible. Unfortunately, the large size of code bases and lack of developer expertise can make discovering software vulnerabilities difficult. A number of vulnerability discovery techniques are available, each with their own strengths. Objective: The objective of this research is to aid in the selection of vulnerability discovery techniques by comparing the vulnerabilities detected by each and comparing their efficiencies. Method: We conducted three case studies using three electronic health record systems to compare four vulnerability discovery techniques: exploratory manual penetration testing, systematic manual penetration testing, automated penetration testing, and automated static analysis. Results: In our case study, we found empirical evidence that no single technique discovered every type of vulnerability. We discovered that the specific set of vulnerabilities identified by one tool was largely orthogonal to that of other tools. Systematic manual penetration testing found the most design flaws, while automated static analysis found the most implementation bugs. The most efficient discovery technique in terms of vulnerabilities discovered per hour was automated penetration testing. Conclusion: The results show that employing a single technique for vulnerability discovery is insufficient for finding all types of vulnerabilities. Each technique identified only a subset of the vulnerabilities, which, for the most part were independent of each other. Our results suggest that in order to discover the greatest variety of vulnerability types, at least systematic manual penetration testing and automated static analysis should be performed. ?? 2013 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2012.11.007},
  file          = {:article\\-A comparison of the efficiency and effectiveness of vulnerability discovery techniques.pdf:PDF},
  groups        = {vice-important},
  isbn          = {0950-5849},
  issn          = {09505849},
  keywords      = {Black box testing, Penetration testing, Security, Static analysis, Vulnerability, White box testing, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank3},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2012.11.007},
}

@Article{Vanegue2013,
  author        = {Vanegue, Julien and Lahiri, Shuvendu K.},
  title         = {{Towards practical reactive security audit using extended static checkers}},
  journal       = {Proceedings - IEEE Symposium on Security and Privacy},
  year          = {2013},
  pages         = {33--47},
  __markedentry = {[ccc:3]},
  abstract      = {This paper describes our experience of performing reactive security audit of known security vulnerabilities in core operating system and browser COM components, using an extended static checker HAVOCLITE. We describe the extensions made to the tool to be applicable on such large C++ components, along with our experience of using an extended static checker in the large. We argue that the use of such checkers as a configurable static analysis in the hands of security auditors can be an effective tool for finding variations of known vulnerabilities. The effort has led to finding and fixing around 70 previously unknown security vulnerabilities in over 10 millions lines operating system and browser code.},
  doi           = {10.1109/SP.2013.12},
  file          = {:article\\Towards practical reactive security audit using  extended static checkers.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9780769549774},
  issn          = {10816011},
  keywords      = {binary, extended static checking, first select, fuzz, obfuscate, program verification, second select, security audit, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank3},
  mendeley-tags = {binary,first select,fuzz,obfuscate,second select,source code,source code-important,source code-vice important,web},
}

@Article{Rahimi2013,
  author        = {Rahimi, Sanaz and Zargham, Mehdi},
  title         = {{Vulnerability scrying method for software vulnerability discovery prediction without a vulnerability database}},
  journal       = {IEEE Transactions on Reliability},
  year          = {2013},
  volume        = {62},
  number        = {2},
  pages         = {395--407},
  __markedentry = {[ccc:6]},
  abstract      = {Predicting software vulnerability discovery trends can help improve secure deployment of software applications and facilitate backup provisioning, disaster recovery, diversity planning, and maintenance scheduling. Vulnerability discovery models (VDMs) have been studied in the literature as a means to capture the underlying stochastic process. Based on the VDMs, a few vulnerability prediction schemes have been proposed. Unfortunately, all these schemes suffer from the same weaknesses: they require a large amount of historical vulnerability data from a database (hence they are not applicable to a newly released software application), their precision depends on the amount of training data, and they have significant amount of error in their estimates. In this work, we propose vulnerability scrying, a new paradigm for vulnerability discovery prediction based on code properties. Using compiler-based static analysis of a codebase, we extract code properties such as code complexity (cyclomatic complexity), and more importantly code quality (compliance with secure coding rules), from the source code of a software application. Then we propose a stochastic model which uses code properties as its parameters to predict vulnerability discovery. We have studied the impact of code properties on the vulnerability discovery trends by performing static analysis on the source code of four real-world software applications. We have used our scheme to predict vulnerability discovery in three other software applications. The results show that even though we use no historical data in our prediction, vulnerability scrying can predict vulnerability discovery with better precision and less divergence over time.},
  doi           = {10.1109/TR.2013.2257052},
  file          = {:article\\Vulnerability scrying method for software vulnerability discovery prediction without a vulnerability database.pdf:pdf},
  groups        = {vice-important},
  issn          = {00189529},
  keywords      = {Code security,binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,vulnerability discovery model,vulnerability prediction,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Shar2013,
  author        = {Shar, Lwin Khin and Tan, Hee Beng Kuan},
  title         = {{Predicting SQL injection and cross site scripting vulnerabilities through mining input sanitization patterns}},
  journal       = {Information and Software Technology},
  year          = {2013},
  volume        = {55},
  number        = {10},
  pages         = {1767--1780},
  __markedentry = {[ccc:6]},
  abstract      = {Context SQL injection (SQLI) and cross site scripting (XSS) are the two most common and serious web application vulnerabilities for the past decade. To mitigate these two security threats, many vulnerability detection approaches based on static and dynamic taint analysis techniques have been proposed. Alternatively, there are also vulnerability prediction approaches based on machine learning techniques, which showed that static code attributes such as code complexity measures are cheap and useful predictors. However, current prediction approaches target general vulnerabilities. And most of these approaches locate vulnerable code only at software component or file levels. Some approaches also involve process attributes that are often difficult to measure. Objective This paper aims to provide an alternative or complementary solution to existing taint analyzers by proposing static code attributes that can be used to predict specific program statements, rather than software components, which are likely to be vulnerable to SQLI or XSS. Method From the observations of input sanitization code that are commonly implemented in web applications to avoid SQLI and XSS vulnerabilities, in this paper, we propose a set of static code attributes that characterize such code patterns. We then build vulnerability prediction models from the historical information that reflect proposed static attributes and known vulnerability data to predict SQLI and XSS vulnerabilities. Results We developed a prototype tool called PhpMinerI for data collection and used it to evaluate our models on eight open source web applications. Our best model achieved an averaged result of 93{\%} recall and 11{\%} false alarm rate in predicting SQLI vulnerabilities, and 78{\%} recall and 6{\%} false alarm rate in predicting XSS vulnerabilities. Conclusion The experiment results show that our proposed vulnerability predictors are useful and effective at predicting SQLI and XSS vulnerabilities. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.infsof.2013.04.002},
  file          = {:article\\Predicting SQL injection and cross site scripting vulnerabilities through mining input sanitization patterns.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9781467310673},
  issn          = {09505849},
  keywords      = {Data mining,Empirical study,Input sanitization,Static code attributes,Vulnerability prediction,Web application vulnerability,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2013.04.002},
}

@Article{Mou2013,
  author        = {Mou, Lili and Li, Ge and Liu, Yuxuan and Peng, Hao and Jin, Zhi and Xu, Yan and Zhang, Lu},
  title         = {{Knowledge Science, Engineering and Management}},
  year          = {2013},
  volume        = {8041},
  __markedentry = {[ccc:6]},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1409.3358v1},
  doi           = {10.1007/978-3-642-39787-5},
  eprint        = {arXiv:1409.3358v1},
  groups        = {imprortant},
  isbn          = {978-3-642-39786-8},
  keywords      = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://link.springer.com/10.1007/978-3-642-39787-5},
}

@Article{Yamaguchi2014,
  author        = {Yamaguchi, Fabian and Golde, Nico and Arp, Daniel and Rieck, Konrad},
  title         = {{Modeling and discovering vulnerabilities with code property graphs}},
  journal       = {Proceedings - IEEE Symposium on Security and Privacy},
  year          = {2014},
  pages         = {590--604},
  __markedentry = {[ccc:5]},
  abstract      = {The vast majority of security breaches encountered today are a direct result of insecure code. Consequently, the protection of computer systems critically depends on the rigorous identification of vulnerabilities in software, a tedious and error-prone process requiring significant expertise. Unfortunately, a single flaw suffices to undermine the security of a system and thus the sheer amount of code to audit plays into the attacker's cards. In this paper, we present a method for effectively mining large amounts of source code for vulnerabilities. To this end, we introduce a novel representation of source code called a code property graph that merges concepts of classic program analysis, namely abstract syntax trees, control flow graphs and program dependence graphs, into a joint data structure. This comprehensive representation enables us to elegantly model templates for common vulnerabilities with graph traversals that, for instance, can identify buffer overflows, integer overflows, format string vulnerabilities, or memory disclosures. We implement our approach using a popular graph database and demonstrate its efficacy by identifying 18 previously unknown vulnerabilities in the source code of the Linux kernel.},
  doi           = {10.1109/SP.2014.44},
  file          = {:article\\Modeling and discovering vulnerabilities with code property graphs.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781479946860},
  issn          = {10816011},
  keywords      = {Graph Databases, Static Analysis, Vulnerabilities, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Rasthofer2014,
  author        = {Rasthofer, Siegfried and Arzt, Steven and Bodden, Eric},
  title         = {{A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks}},
  journal       = {Proceedings 2014 Network and Distributed System Security Symposium},
  year          = {2014},
  number        = {February},
  pages         = {23--26},
  __markedentry = {[ccc:6]},
  abstract      = {{\#}SUSI. They do static analysis (machine learning) to detect sources and sinks, and they categorized them. Features: method name, parameters, value type, parameter type (is interface?), modifiers, class modifiers, name, dataflow to return, dataflow to return, to sink, abstract sink, required permission. For category, class name, method invocation, body contents, parameter type and return value type.},
  doi           = {10.14722/ndss.2014.23039},
  file          = {:article\\A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks(2).pdf:pdf},
  groups        = {vice-important},
  isbn          = {1-891562-35-5},
  keywords      = {first select,machine learning,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {first select,machine learning,second select,source code,source code-important,source code-vice important},
  url           = {http://www.internetsociety.org/doc/machine-learning-approach-classifying-and-categorizing-android-sources-and-sinks},
}

@Article{Shepperd2014,
  author        = {Shepperd, Martin and Bowes, David and Hall, Tracy},
  title         = {{Researcher bias: The use of machine learning in software defect prediction}},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2014},
  volume        = {40},
  number        = {6},
  pages         = {603--616},
  __markedentry = {[ccc:6]},
  abstract      = {Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect onpredictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build arandom effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion. To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.},
  doi           = {10.1109/TSE.2014.2322358},
  groups        = {vice-important},
  issn          = {00985589},
  keywords      = {Software defect prediction,binary,first select,machine learning,malware,meta-analysis,predicte,researcher bias,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {binary,first select,machine learning,malware,predicte,second select,source code,source code-important,source code-vice important},
}

@Article{Rasthofer2014a,
  author        = {Rasthofer, Siegfried and Arzt, Steven and Bodden, Eric},
  title         = {{A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks}},
  journal       = {Proceedings 2014 Network and Distributed System Security Symposium},
  year          = {2014},
  number        = {February},
  pages         = {23--26},
  __markedentry = {[ccc:6]},
  abstract      = {{\#}SUSI. They do static analysis (machine learning) to detect sources and sinks, and they categorized them. Features: method name, parameters, value type, parameter type (is interface?), modifiers, class modifiers, name, dataflow to return, dataflow to return, to sink, abstract sink, required permission. For category, class name, method invocation, body contents, parameter type and return value type.},
  doi           = {10.14722/ndss.2014.23039},
  file          = {:article\\A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks.pdf:pdf},
  groups        = {vice-important},
  isbn          = {1-891562-35-5},
  keywords      = {android,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {android,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://www.internetsociety.org/doc/machine-learning-approach-classifying-and-categorizing-android-sources-and-sinks},
}

@Article{Thung2014,
  author        = {Thung, Ferdian and Lucia and Lo, David and Jiang, Lingxiao and Rahman, Foyzur and Devanbu, Premkumar T.},
  title         = {{To what extent could we detect field defects? An extended empirical study of false negatives in static bug-finding tools}},
  journal       = {Automated Software Engineering},
  year          = {2014},
  volume        = {22},
  number        = {4},
  pages         = {561--602},
  __markedentry = {[ccc:6]},
  annote        = {对false positive的成因进行探讨},
  doi           = {10.1007/s10515-014-0169-8},
  groups        = {imprortant},
  issn          = {15737535},
  keywords      = {Empirical study,False negatives,Static bug-finding tools,first select,second select,source code,source code-important,source code-vice important},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  publisher     = {Springer US},
  url           = {http://dx.doi.org/10.1007/s10515-014-0169-8},
}

@Article{Rockai2014,
  author        = {Rockai, P. and Barnat, J. and Brim, L.},
  title         = {{Model Checking C++ with Exceptions}},
  year          = {2014},
  volume        = {70},
  __markedentry = {[ccc:6]},
  file          = {:article\\Model Checking C++ with Exceptions.pdf:PDF},
  groups        = {vice-important},
  keywords      = {binary,earliest-deadline-f,first select,model-checking, task automata, earliest-deadline-f,second select,source code,source code-important,source code-vice important,task automata},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
}

@Article{Khedker2014,
  author        = {Khedker, Uday P.},
  title         = {{Buffer Overflow Analysis for C}},
  year          = {2014},
  __markedentry = {[ccc:4]},
  abstract      = {Buffer overflow detection and mitigation for C programs has been an important concern for a long time. This paper defines a string buffer overflow analysis for C programs. The key ideas of our formulation are (a) separating buffers from the pointers that point to them, (b) modelling buffers in terms of sizes and sets of positions of null characters, and (c) defining stateless functions to compute the sets of null positions and mappings between buffers and pointers.   This exercise has been carried out to test the feasibility of describing such an analysis in terms of lattice valued functions and relations to facilitate automatic construction of an analyser without the user having to write C/C++/Java code. This is facilitated by devising stateless formulations because stateful formulations combine features through side effects in states raising a natural requirement of C/C++/Java code to be written to describe them. Given the above motivation, the focus of this paper is not to build good static approximations for buffer overflow analysis but to show how given static approximations could be formalized in terms of stateless formulations so that they become amenable to automatic construction of analysers.},
  archiveprefix = {arXiv},
  arxivid       = {1412.5400},
  eprint        = {1412.5400},
  file          = {:article\\Buffer Overflow Analysis for C.pdf:pdf},
  groups        = {imprortant},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://arxiv.org/abs/1412.5400},
}

@InProceedings{Manohar2014,
  author        = {Manohar, Lakshmi and Velicheti, Rao and Feiock, Dennis C and Peiris, Manjula and Raje, Rajeev and Hill, James H},
  title         = {{Towards Modeling the Behavior of Static Code Analysis Tools}},
  booktitle     = {2014 9th Cyber and Information Security Research Conference},
  year          = {2014},
  __markedentry = {[ccc:4]},
  abstract      = {This paper presents preliminary results of an independent study to assess the performance of a static code analysis (SCA) tool's abil- ity to detect and identify weaknesses and vulnerabilities in source code. The goal of the study is to model the behavior of static code analysis tools, and predict what SCA tool, or set of SCA tools, should be applied against a given source code to identify weak- nesses and vulnerabilities.},
  file          = {:article\\Towards Modeling the Behavior of Static Code Analysis Tools.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781450328128},
  keywords      = {behavior, evaluation, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, static code analysis tools, rank4},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important},
}

@InProceedings{Ia-Ferreira2014,
  author        = {Ia-Ferreira, Iv´ an Garc´ and Laorden, Carlos and Santos, Igor and ıa Bringas, Pablo Garc´},
  title         = {{A Survey on Static Analysis and Model Checking}},
  booktitle     = {International Joint Conference SOCO'14-CISIS'14},
  year          = {2014},
  volume        = {239},
  pages         = {761},
  __markedentry = {[ccc:4]},
  doi           = {10.1007/978-3-319-01854-6},
  file          = {:article\\A Survey on Static Analysis and Model Checking.pdf:pdf},
  groups        = {imprortant},
  isbn          = {978-3-319-01853-9},
  issn          = {21945357},
  keywords      = {binary, cohen, first select, linear, packet header anomaly detection, regression analysis, s-d, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, statistical analysis, survey, rank4},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,survey},
  url           = {http://link.springer.com/10.1007/978-3-319-01854-6},
}

@PhdThesis{2014a,
  title         = {{Improving C ++ Software Quality with Static Code Analysis}},
  year          = {2014},
  __markedentry = {[ccc:4]},
  annote        = {对静态分析理论介绍比较全面},
  file          = {:article\\Improving C++ software quality with static code analysis.pdf:PDF},
  groups        = {imprortant},
  keywords      = {binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank4},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
}

@Article{Chen2014,
  author        = {Chen, Kai and Zhang, Yingjun},
  title         = {{Statically-directed dynamic taint analysis}},
  journal       = {Chinese Journal of Electronics},
  year          = {2014},
  volume        = {23},
  number        = {1},
  pages         = {18--24},
  __markedentry = {[ccc:6]},
  file          = {:article\\Statically-directed dynamic taint analysis.pdf:pdf},
  groups        = {vice-important},
  issn          = {10224653},
  keywords      = {Binary code., Dynamic analysis, Statically-directed, Taint analysis, binary, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
}

@Article{Evans2014,
  author        = {Evans, Nathan S. and Benameur, Azzedine and Elder, Matthew},
  title         = {{Large-Scale Evaluation of a Vulnerability Analysis Framework}},
  journal       = {7th Workshop on Cyber Security Experimentation and Test (CSET 14)},
  year          = {2014},
  pages         = {1--8},
  __markedentry = {[ccc:4]},
  file          = {:article\\Large-scale evalution of a vulnerability analysis framework-cset14.pdf:PDF},
  groups        = {imprortant},
  keywords      = {binary, first select, fuzz, obfuscate, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {binary,first select,fuzz,obfuscate,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {https://www.usenix.org/conference/cset14/workshop-program/presentation/benameur},
}

@Article{Abal2014,
  author        = {Abal, Iago},
  title         = {{42 Variability Bugs in the Linux Kernel A Qualitative Study}},
  journal       = {(CCF Rank B)Proceedings of the 29th ACM/IEEE international conference on Automated software engineering(ASE'14)},
  year          = {2014},
  number        = {May},
  pages         = {421--432},
  __markedentry = {[ccc:5]},
  abstract      = {Feature-sensitive verification pursues effective analysis of the exponentially many variants of a program family. However, researchers lack examples of concrete bugs induced by vari-ability, occurring in real large-scale systems. Such a collection of bugs is a requirement for goal-oriented research, serving to evaluate tool implementations of feature-sensitive analyses by testing them on real bugs. We present a qualitative study of 42 variability bugs collected from bug-fixing commits to the Linux kernel repository. We analyze each of the bugs, and record the results in a database. In addition, we provide self-contained simplified C99 versions of the bugs, facilitating understanding and tool evaluation. Our study provides in-sights into the nature and occurrence of variability bugs in a large C software system, and shows in what ways variability affects and increases the complexity of software bugs.},
  doi           = {10.1145/2642937.2642990},
  file          = {:article\\40 Variability Bugs in the Linux Kernel.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9788779493186},
  keywords      = {bugs, feature interactions, first select, fuzz, linux, machine learning, second select, software variability, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,web},
}

@Article{Dahse2014,
  author        = {Dahse, Johannes and Holz, Thorsten},
  title         = {{Static Detection of Second-Order Vulnerabilities in Web Applications}},
  journal       = {23rd USENIX Security Symposium (USENIX Security 14)},
  year          = {2014},
  pages         = {989--1003},
  __markedentry = {[ccc:6]},
  abstract      = {Web applications evolved in the last decades from sim- ple scripts to multi-functional applications. Such com- plex web applications are prone to different types of se- curity vulnerabilities that lead to data leakage or a com- promise of the underlying web server. So called second- order vulnerabilities occur when an attack payload is first stored by the application on the web server and then later on used in a security-critical operation. In this paper, we introduce the first automated static code analysis approach to detect second-order vulnera- bilities and related multi-step exploits in web applica- tions. By analyzing reads and writes to memory loca- tions of the web server, we are able to identify unsani- tized data flows by connecting input and output points of data in persistent data stores such as databases or ses- sion data. As a result, we identified 159 second-order vulnerabilities in six popular web applications such as the conference management systems HotCRP and Open- Conf. Moreover, the analysis of web applications eval- uated in related work revealed that we are able to detect several critical vulnerabilities previously missed.},
  file          = {:article\\Static Detection of Second-Order Vulnerabilities in Web Applications.pdf:pdf},
  groups        = {vice-important},
  isbn          = {978-1-931971-15-7},
  keywords      = {first select,fuzz,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  url           = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/dahse},
}

@Article{Collingbourne2014,
  author        = {Collingbourne, Peter and Cadar, Cristian and Kelly, Paul H J},
  title         = {{Symbolic crosschecking of data-parallel floating-point code}},
  journal       = {IEEE Transactions on Software Engineering},
  year          = {2014},
  volume        = {40},
  number        = {7},
  pages         = {710--737},
  __markedentry = {[ccc:5]},
  abstract      = {We present a symbolic execution-based technique for cross-checking programs accelerated using SIMD or OpenCL against an unaccelerated version, as well as a technique for detecting data races in OpenCL programs. Our techniques are implemented in KLEE-CL, a tool based on the symbolic execution engine KLEE that supports symbolic reasoning on the equivalence between expressions involving both integer and floating-point operations. While the current generation of constraint solvers provide effective support for integer arithmetic, the situation is different for floating-point arithmetic, due to the complexity inherent in such computations. The key insight behind our approach is that floating-point values are only reliably equal if they are essentially built by the same operations. This allows us to use an algorithm based on symbolic expression matching augmented with canonicalisation rules to determine path equivalence. Under symbolic execution, we have to verify equivalence along every feasible control-flow path. We reduce the branching factor of this process by aggressively merging conditionals, if-converting branches into select operations via an aggressive phi-node folding transformation. To support the Intel Streaming SIMD Extension (SSE) instruction set, we lower SSE instructions to equivalent generic vector operations, which in turn are interpreted in terms of primitive integer and floating-point operations. To support OpenCL programs, we symbolically model the OpenCL environment using an OpenCL runtime library targeted to symbolic execution. We detect data races by keeping track of all memory accesses using a memory log, and reporting a race whenever we detect that two accesses conflict. By representing the memory log symbolically, we are also able to detect races associated with symbolically-indexed accesses of memory objects. We used KLEE-CL to prove the bounded equivalence between scalar and data-parallel versions of floating-point programs and find a number - f issues in a variety of open source projects that use SSE and OpenCL, including mismatches between implementations, memory errors, race conditions and a compiler bug.},
  doi           = {10.1109/TSE.2013.2297120},
  file          = {:article\\Symbolic crosschecking of data-parallel floating-point code.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781450306348},
  issn          = {00985589},
  keywords      = {Data-parallel code, KLEE-CL, OpenCL, SIMD, binary, first select, floating point, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, symbolic execution, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
  pmid          = {6698391},
}

@Article{Mokhov2014,
  author        = {Mokhov, Serguei A. and Paquet, Joey and Debbabi, Mourad},
  title         = {{The use of NLP techniques in static code analysis to detect weaknesses and vulnerabilities}},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  year          = {2014},
  volume        = {8436 LNAI},
  pages         = {326--332},
  __markedentry = {[ccc:1]},
  doi           = {10.1007/978-3-319-06483-3_33},
  file          = {:article\\The use of NLP techniques in static code analysis to detect weaknesses and vulnerabilities.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9783319064826},
  issn          = {16113349},
  keywords      = {binary, first select, machine learning, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank1},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Yu2014,
  author        = {Yu, Fang and Alkhalaf, Muath and Bultan, Tevfik and Ibarra, Oscar H.},
  title         = {{Automata-based symbolic string analysis for vulnerability detection}},
  journal       = {Formal Methods in System Design},
  year          = {2014},
  volume        = {44},
  number        = {1},
  pages         = {44--70},
  __markedentry = {[ccc:6]},
  abstract      = {Verifying string manipulating programs is a crucial problem in com- puter security. String operations are used extensively within web applications to manipulate user input, and their erroneous use is the most common cause of security vulnerabilities in web applications. We present an automata-based approach for symbolic analysis of string manipulating programs.We use deter- ministic finite automata (DFAs) to represent possible values of string variables. Using forward reachability analysis we compute an over-approximation of all possible values that string variables can take at each program point. Inter- secting these with a given attack pattern yields the potential attack strings if the program is vulnerable. Based on the presented techniques, we have imple- mented Stranger, an automata-based string analysis tool for detecting string- related security vulnerabilities in PHP applications. We evaluated Stranger on several open-source Web applications including one with 350,000+ lines of code. Stranger is able to detect known/unknown vulnerabilities, and, after in- serting proper sanitization routines, prove the absence of vulnerabilities with respect to given attack patterns.},
  doi           = {10.1007/s10703-013-0189-1},
  file          = {:article\\Automata-based symbolic string analysis for vulnerability detection.pdf:pdf},
  groups        = {vice-important},
  isbn          = {1070301301891},
  issn          = {09259856},
  keywords      = {Automated verification, String analysis, Vulnerability analysis, Web application security, binary, first select, second select, source code, source code-important, source code-vice important, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Kulenovic2014,
  author        = {Kulenovic, Melina and Donko, Dzenana},
  title         = {{A survey of static code analysis methods for security vulnerabilities detection}},
  journal       = {2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics, MIPRO 2014 - Proceedings},
  year          = {2014},
  number        = {May},
  pages         = {1381--1386},
  __markedentry = {[ccc:2]},
  doi           = {10.1109/MIPRO.2014.6859783},
  file          = {:article\\A survey of static code analysis methods for security vulnerabilities detection.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9789532330816},
  keywords      = {first select, predicte, second select, security, source code, source code-important, source code-vice important, stat, static analysi, static analysis, static code analysis, survey, vulnerability, web, rank2},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,survey,web},
}

@Article{Gupta2014,
  author        = {Gupta, Mukesh Kumar and Govil, M. C. and Singh, Girdhari},
  title         = {{Static analysis approaches to detect SQL injection and cross site scripting vulnerabilities in web applications: A survey}},
  journal       = {International Conference on Recent Advances and Innovations in Engineering, ICRAIE 2014},
  year          = {2014},
  pages         = {9--13},
  __markedentry = {[ccc:6]},
  abstract      = {Dependence on web applications is increasing very rapidly in recent time for social communications, health problem, financial transaction and many other purposes. Unfortunately, presence of security weaknesses in web applications allows malicious user's to exploit various security vulnerabilities and become the reason of their failure. Currently, SQL Injection (SQLI) and Cross-Site Scripting (XSS) vulnerabilities are most dangerous security vulnerabilities exploited in various popular web applications i.e. eBay, Google, Facebook, Twitter etc. Research on defensive programming, vulnerability detection and attack prevention techniques has been quite intensive in the past decade. Defensive programming is a set of coding guidelines to develop secure applications. But, mostly developers do not follow security guidelines and repeat same type of programming mistakes in their code. Attack prevention techniques protect the applications from attack during their execution in actual environment. The difficulties associated with accurate detection of SQLI and XSS vulnerabilities in coding phase of software development life cycle. This paper proposes a classification of software security approaches used to develop secure software in various phase of software development life cycle. It also presents a survey of static analysis based approaches to detect SQL Injection and cross-site scripting vulnerabilities in source code of web applications. The aim of these approaches is to identify the weaknesses in source code before their exploitation in actual environment. This paper would help researchers to note down future direction for securing legacy web applications in early phases of software development life cycle.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1011.1669v3},
  doi           = {10.1109/ICRAIE.2014.6909173},
  eprint        = {arXiv:1011.1669v3},
  file          = {:article\\Static Analysis Approaches to Detect SQL Injection.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9781479940400},
  issn          = {`},
  keywords      = {SQL injection, cross site scripting, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, survey, vulnerabilitie, web, web applicatio, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,survey,web},
  pmid          = {25246403},
}

@Article{Seo2014,
  author        = {Seo, Seung Hyun and Gupta, Aditi and Sallam, Asmaa Mohamed and Bertino, Elisa and Yim, Kangbin},
  title         = {{Detecting mobile malware threats to homeland security through static analysis}},
  journal       = {Journal of Network and Computer Applications},
  year          = {2014},
  volume        = {38},
  number        = {1},
  pages         = {43--53},
  __markedentry = {[ccc:6]},
  abstract      = {Recent years have seen the significant increase in the popularity of smartphones. This popularity has been accompanied with an equally alarming rise in mobile malware. Recently released mobile malware targeting Android devices have been found to specifically focus on root exploits to obtain root-level access and execute instructions from a remote server. Thus, this kind of mobile malware presents a significant threat to Homeland Security. This is possible because smartphones can serve as zombie devices which are then controlled by hackers' via a C{\&}C server. In this paper, we discuss the defining characteristics inherent in mobile malware and show mobile attack scenarios which are feasible against Homeland Security. We also propose a static analysis tool, DroidAnalyzer, which identifies potential vulnerabilities of Android apps and the presence of root exploits. Then, we analyze various mobile malware samples and targeting apps such as banking, flight tracking and booking, home{\&}office monitoring apps to examine potential vulnerabilities by applying DroidAnalyzer. ?? 2013 Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.jnca.2013.05.008},
  file          = {:article\\Detecting mobile malware threats to homeland security through tatic analysis.pdf:PDF},
  groups        = {vice-important},
  isbn          = {1084-8045},
  issn          = {10848045},
  keywords      = {Android OS, Homeland security, Mobile malware, Smartphone, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier},
  url           = {http://dx.doi.org/10.1016/j.jnca.2013.05.008},
}

@Article{Scandariato2014,
  author        = {Scandariato, Riccardo and Walden, James and Hovsepyan, Aram and Joosen, Wouter},
  title         = {{Predicting Vulnerable Software Components via Text Mining}},
  year          = {2014},
  volume        = {40},
  number        = {10},
  pages         = {993--1006},
  __markedentry = {[ccc:6]},
  file          = {:article\\Predicting Vulnerable Software Components via Text Mining.pdf:pdf},
  groups        = {vice-important},
  keywords      = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Fang2014,
  author        = {Fang, Ming and Hafiz, Munawar},
  title         = {{Discovering Buffer Overflow Vulnerabilities in the Wild: An Empirical Study}},
  journal       = {Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
  year          = {2014},
  pages         = {23:1----23:10},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Reporters of security vulnerabilities possess rich information about the security engineering process. Goal: We performed an empirical study on reporters of buffer overflow vulnerabilities to understand the methods and tools used during the discovery. Method: We ran the study in the form of an email questionnaire with open ended questions. The participants were reporters featured in the SecurityFocus repository during two six-month periods; we collected 58 responses. Results: We found that in spite of many apparent choices, reporters follow similar approaches. Most reporters typically use fuzzing, but their fuzzing tools are created ad hoc; they use a few debugging tools to analyze the crash introduced by a fuzzer; and static analysis tools are rarely used. We also found a serious problem in the vulnerability reporting process. Most reporters, especially the experienced ones, favor full-disclosure and do not collaborate with the vendors of vulnerable software. They think that the public disclosure, sometimes supported by a detailed exploit, will put pressure on vendors to fix the vulnerabilities. But, in practice, the vulnerabilities not reported to vendors are less likely to be fixed. Conclusions: The results are valuable for beginners exploring how to detect and report buffer overflows and for tool vendors and researchers exploring how to automate and fix the process. },
  doi           = {10.1145/2652524.2652533},
  file          = {:article\\Discovering buffer overflow vulnerabilities in the wild_an empirical study.pdf:PDF},
  groups        = {vice-important},
  isbn          = {978-1-4503-2774-9},
  issn          = {19493789},
  keywords      = {binary,empirical study,first select,fuzz,machine learning,predicte,second select,secure software engineering,source code,source code-important,source code-vice important,stat,static analysi,static analysis,vulnerability,web},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://doi.acm.org/10.1145/2652524.2652533},
}

@Article{Padmanabhuni2015,
  author        = {Padmanabhuni, Bindu Madhavi and Tan, Hee Beng Kuan},
  title         = {{Buffer Overflow Vulnerability Prediction from x86 Executables Using Static Analysis and Machine Learning}},
  journal       = {2015 IEEE 39th Annual Computer Software and Applications Conference},
  year          = {2015},
  pages         = {450--459},
  __markedentry = {[ccc:6]},
  annote        = {本文是对预测二进制程序中的漏洞，参考下，并获取文中关于source code预测方法的信息和评价},
  doi           = {10.1109/COMPSAC.2015.78},
  file          = {:article\\Buffer Overflow Vulnerability Prediction from x86 executables using Static.pdf:PDF},
  groups        = {vice-important},
  isbn          = {978-1-4673-6564-2},
  issn          = {07303157},
  keywords      = {- binary static analysis,and data dependency,binary,buffer overflow,buffer usage pattern,control,disassembly,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,static code attributes,vulnerability prediction},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7273653},
}

@Article{Muntean2015,
  author        = {Muntean, Paul and Rahman, Mustafizur and Ibing, Andreas and Eckert, Claudia},
  title         = {{SMT-constrained symbolic execution engine for integer overflow detection in C code}},
  journal       = {2015 Information Security for South Africa (ISSA)},
  year          = {2015},
  number        = {3},
  pages         = {1--8},
  __markedentry = {[ccc:5]},
  abstract      = {{\textcopyright} 2015 IEEE. Integer overflow errors in C programs are difficult to detect since the C language specification rules which govern how one can cast or promote integer types are not accompanied by any unambiguous set of formal rules. Thus, making it difficult for the programmer to understand and use the rules correctly causing vulnerabilities or costly errors. Although there are many static and dynamic tools used for integer overflow detection, the tools lack the capacity of efficiently filtering out false positives and false negatives. Better tools are needed to be constructed which are more precise in regard to bug detection and filtering out false positives. In this paper, we present an integer overflow checker which is based on precise modeling of C language semantics and symbolic function models. We developed our checker as an Eclipse plug-in and tested it on the open source C/C++ test case CWE-190 contained in the National Institute of Standards and Technology (NIST) Juliet test suite for C/C++. We ran our checker systematically on 2592 programs having in total 340 KLOC with a true positive rate of 95.49{\%} for the contained C programs and with no false positives. We think our approach is effective to be applied in future to C++ programs as well, in order to detect other kinds of vulnerabilities related to integers.},
  doi           = {10.1109/ISSA.2015.7335070},
  file          = {:article\\SMT-constrained symbolic execution engine for integer overflow detection in C code.pdf:pdf},
  groups        = {imprortant},
  isbn          = {978-1-4799-7755-0},
  keywords      = {C code, C language semantics, C language specification rules, C programs, C++ language, C++ programs, CWE-190, Eclipse plug-in, KLOC, Lead, NIST Juliet test suite, National Institute of Standards and Technology, SMT-constrained symbolic execution engine, Yttrium, binary, bug detection, bug filtering, context-sensitive analysis, dynamic tools, false negatives, false positives, first select, formal rules, fuzz, information security, integer overflow checker, integer overflow error detection, integer types, open source C test case, open source C++ test case, program debugging, program testing, safety-critical software, second select, software vulnerability, source code, source code-important, source code-vice important, stat, static analysi, static analysis, static tools, symbolic function models, rank5},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7335070},
}

@Article{Hui2015,
  author        = {Hui, Deng and Hui, Liu and Ying, Guo and Baofeng, Zhang},
  title         = {{Memory Allocation Vulnerability Analysis and Analysis Optimization for C Programs Based on Formal Methods}},
  journal       = {Journal of Software},
  year          = {2015},
  volume        = {10},
  number        = {9},
  pages         = {1079--1085},
  __markedentry = {[ccc:5]},
  doi           = {10.17706/jsw.10.9.1079-1085},
  file          = {:article\\Memory Allocation Vulnerability Analysis and Analysis Optimization for C Programs Based on Formal Methods.pdf:pdf},
  groups        = {imprortant},
  issn          = {1796217X},
  keywords      = {algebraic transition system, bisimulation, c program, first select, formal, fuzz, memory allocation vulnerability, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important},
  url           = {http://www.jsoftware.us/index.php?m=content{\&}c=index{\&}a=show{\&}catid=156{\&}id=2525},
}

@Article{Urma2015,
  author        = {Urma, Raoul Gabriel and Mycroft, Alan},
  title         = {{Source-code queries with graph databases - With application to programming language usage and evolution}},
  journal       = {Science of Computer Programming},
  year          = {2013},
  volume        = {97},
  number        = {P1},
  pages         = {127--134},
  __markedentry = {[ccc:5]},
  abstract      = {Program querying and analysis tools are of growing importance, and occur in two main variants. Firstly there are source-code query languages which help software engineers to explore a system, or to find code in need of refactoring as coding standards evolve. These also enable language designers to understand the practical uses of language features and idioms over a software corpus. Secondly there are program analysis tools in the style of Coverity which perform deeper program analysis searching for bugs as well as checking adherence to coding standards such as MISRA. The former class are typically implemented on top of relational or deductive databases and make ad-hoc trade-offs between scalability and the amount of source-code detail held - with consequent limitations on the expressiveness of queries. The latter class are more commercially driven and involve more ad-hoc queries over program representations, nonetheless similar pressures encourage user-visible domain-specific languages to specify analyses. We argue that a graph data model and associated query language provides a unifying conceptual model and gives efficient scalable implementation even when storing full source-code detail. It also supports overlays allowing a query DSL to pose queries at a mixture of syntax-tree, type, control-flow-graph or data-flow levels. We describe a prototype source-code query system built on top of Neo4j using its Cypher graph query language; experiments show it scales to multi-million-line programs while also storing full source-code detail.},
  doi           = {10.1016/j.scico.2013.11.010},
  file          = {:article\\Source-code queries with graph databases—with application to programming language usage and evolution.pdf:PDF},
  groups        = {imprortant},
  issn          = {01676423},
  keywords      = {Graph databases, Programming language evolution, Source-code queries and DSLs, binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.scico.2013.11.010},
}

@Article{Huuck2015,
  author        = {Huuck, Ralf},
  title         = {{Technology transfer: Formal analysis, engineering, and business value}},
  journal       = {Science of Computer Programming},
  year          = {2015},
  volume        = {103},
  pages         = {3--12},
  __markedentry = {[ccc:5]},
  abstract      = {In this work we report on our experiences on developing and commercializing Goanna, a source code analyzer for detecting software bugs and security vulnerabilities in C/C++ code. Goanna is based on formal software analysis techniques such as model checking, static analysis and SMT solving. The commercial version of Goanna is currently deployed in a wide range of organizations around the world. Moreover, the underlying technology is licensed to an independent software vendor with tens of thousands of customers, making it possibly one of the largest deployments of automated formal methods technology. This paper explains some of the challenges as well as the positive results that we encountered in the technology transfer process. In particular, we provide some background on the design decisions and techniques to deal with large industrial code bases, we highlight engineering challenges and efforts that are typically outside of a more academic setting, and we address core aspects of the bigger picture for transferring formal techniques into commercial products, namely, the adoption of such technology and the value for purchasing organizations. While we provide a particular focus on Goanna and our experience with that underlying technology, we believe that many of those aspects hold true for the wider field of formal analysis and verification technology and its adoption in industry.},
  doi           = {10.1016/j.scico.2014.11.003},
  file          = {:article\\Technology transfer_Formal analysis, engineering, and business value.pdf:PDF},
  groups        = {imprortant},
  issn          = {01676423},
  keywords      = {Experience report, Industrial application, Model checking, SMT solving, Static analysis, binary, first select, machine learning, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {binary,first select,machine learning,second select,source code,source code-important,source code-vice important},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.scico.2014.11.003},
}

@Article{Dewey2015,
  author        = {Dewey, David and Reaves, Bradley and Traynor, Patrick},
  title         = {{Uncovering use-after-free conditions in compiled code}},
  journal       = {Proceedings - 10th International Conference on Availability, Reliability and Security, ARES 2015},
  year          = {2015},
  pages         = {90--99},
  __markedentry = {[ccc:6]},
  doi           = {10.1109/ARES.2015.61},
  file          = {:article\\Uncovering Use-After-Free Conditions.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9781467365901},
  keywords      = {Binary Decompilation,Software Security,Static Analysis,binary,first select,obfuscate,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {binary,first select,obfuscate,second select,source code,source code-important,source code-vice important},
}

@Article{Johnson2015,
  author        = {Johnson, Andrew and Waye, Lucas and Moore, Scott and Chong, Stephen},
  title         = {{Exploring and enforcing security guarantees via program dependence graphs}},
  journal       = {Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation - PLDI 2015},
  year          = {2015},
  pages         = {291--302},
  __markedentry = {[ccc:2]},
  abstract      = {We present PIDGIN, a program analysis and understanding tool that enables the specification and enforcement of precise application-specific information security guarantees. PIDGIN also allows developers to interactively explore the information flows in their applications to develop policies and investigate counter-examples. PIDGIN combines program dependence graphs (PDGs), which precisely capture the information flows in a whole application, with a custom PDG query language. Queries express properties about the paths in the PDG; because paths in the PDG correspond to information flows in the application, queries can be used to specify global security policies. PIDGIN is scalable. Generating a PDG for a 330k line Java application takes 90 seconds, and checking a policy on that PDG takes under 14 seconds. The query language is expressive, supporting a large class of precise, application-specific security guarantees. Policies are separate from the code and do not interfere with testing or development, and can be used for security regression testing. We describe the design and implementation of PIDGIN and report on using it: (1) to explore information security guarantees in legacy programs; (2) to develop and modify security policies concurrently with application development; and (3) to develop policies based on known vulnerabilities.},
  doi           = {10.1145/2737924.2737957},
  file          = {:article\\Exploring and enforcing security guarantees via program dependence graphs.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781450334686},
  issn          = {15232867},
  keywords      = {application-specific security, first select, graph, graph query language, program dependence, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank2},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://dl.acm.org/citation.cfm?doid=2737924.2737957},
}

@Article{Gao2015,
  author        = {Gao, Qing and Xiong, Yingfei and Mi, Yaqing and Zhang, Lu and Yang, Weikun and Zhou, Zhaoping and Xie, Bing and Mei, Hong},
  title         = {{Safe memory-leak fixing for C programs}},
  journal       = {Proceedings - International Conference on Software Engineering},
  year          = {2015},
  volume        = {1},
  number        = {1},
  pages         = {459--470},
  __markedentry = {[ccc:4]},
  abstract      = {Automatic bug fixing has become a promising direction for reducing manual effort in debugging. However, general approaches to automatic bug fixing may face some fundamental difficulties. In this paper, we argue that automatic fixing of specific types of bugs can be a useful complement. This paper reports our first attempt towards automatically fixing memory leaks in C programs. Our approach generates only safe fixes, which are guaranteed not to interrupt normal execution of the program. To design such an approach, we have to deal with several challenging problems such as inter-procedural leaks, global variables, loops, and leaks from multiple allocations. We propose solutions to all the problems and integrate the solutions into a coherent approach. We implemented our inter-procedural memory leak fixing into a tool named Leak Fix and evaluated Leak Fix on 15 programs with 522k lines of code. Our evaluation shows that Leak Fix is able to successfully fix a substantial number of memory leaks, and Leak Fix is scalable for large applications.},
  doi           = {10.1109/ICSE.2015.64},
  file          = {:article\\Safe memory-leak fixing for C programs.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781479919345},
  issn          = {02705257},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Xiao-jun2015,
  author        = {Xiao-jun, Q I N and Zuo-ning, Chen and Lin-zhang, Wang},
  title         = {一种基于特征矩阵的软件脆弱性代码克隆检测方法},
  year          = {2015},
  volume        = {26},
  number        = {2},
  pages         = {348--363},
  __markedentry = {[ccc:6]},
  doi           = {10.13328/j.cnki.jos.004786},
  file          = {:article\\一种基于特征矩阵的软件脆弱性代码克隆检测方法.pdf:pdf},
  groups        = {vice-important},
  issn          = {10009825},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@PhdThesis{Ramos2015,
  author        = {Ramos, David A},
  title         = {{UNDER-CONSTRAINED SYMBOLIC EXECUTION:CORRECTNESS CHECKING FOR REAL CODE}},
  year          = {2015},
  __markedentry = {[ccc:5]},
  abstract      = {Software defects pose a frequent challenge to developers, and their consequences are far- reaching. Despite advances in software engineering practices, programming language design, and debugging tools, bugs remain ubiquitous. Traditional testing techniques, while useful, have failed to prevent a significant number of bugs from affecting end users. One promising technique for automatically detecting bugs is dynamic symbolic execu- tion, which aims to test all possible execution paths through a program and identify inputs that cause the program to crash. Unfortunately, symbolic execution suffers from the well- known path explosion problem because the number of distinct execution paths through a program is, in the best case, exponential in the number of branch statements. Consequently, symbolic execution tools are typically ineffective for programs consisting of more than a few thousand lines of code, let alone large codebases with line counts in the millions. This dissertation presents a new, scalable approach to symbolic execution, under- constrained symbolic execution, that targets individual functions rather than whole pro- grams. This technique supports direct symbolic execution of arbitrary C functions and automatically synthesizes their inputs, even for complex, pointer-rich data structures. We demonstrate this technique's feasibility by thoroughly evaluating three use cases, although many others are possible. First, we use it to check the equivalence of library routines from different implementations that share a common interface (e.g., the C standard library). Second, we check whether code patches introduce new bugs by comparing two versions of the same function: before and after a patch is applied. Third, we use under- constrained symbolic execution to test a single version of a function, using a combination of heuristics to separate important errors from those likely to be false positives. In this dissertation, we describe UC-KLEE, a tool we built that implements under- constrained symbolic execution and supports the above use cases. We evaluate our tool on large, mature codebases including BIND, OpenSSL, and the Linux kernel and describe previously-unknown bugs we discovered in each of these codebases.},
  file          = {:article\\Under-constrained symbolic execution_correctness checking for real code sec15-paper-ramos.pdf:PDF},
  groups        = {imprortant},
  keywords      = {binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important},
  number        = {June},
}

@Article{Min2015,
  author        = {Min, Changwoo and Kashyap, Sanidhya and Lee, Byoungyoung and Song, Chengyu and Kim, Taesoo},
  title         = {{Cross-checking semantic correctness}},
  journal       = {Proceedings of the 25th Symposium on Operating Systems Principles - SOSP '15},
  year          = {2015},
  pages         = {361--377},
  __markedentry = {[ccc:5]},
  doi           = {10.1145/2815400.2815422},
  file          = {:article\\Cross-checking semantic correctness the case of finding file system bugs.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781450338349},
  keywords      = {binary, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,second select,source code,source code-important,source code-vice important,web},
  url           = {http://dl.acm.org/citation.cfm?id=2815400.2815422},
}

@Article{Sampaio2015,
  author        = {Sampaio, Luciano and Garcia, Alessandro},
  title         = {{Exploring Context-Sensitive Data Flow Analysis for Early Vulnerability Detection}},
  journal       = {Journal of Systems and Software},
  year          = {2015},
  volume        = {113},
  pages         = {337--361},
  __markedentry = {[ccc:4]},
  abstract      = {Secure programming is the practice of writing programs that are resistant to attacks by malicious people or programs. Programmers of secure software have to be continuously aware of security vulnerabilities when writing their program statements. In order to improve programmers' awareness, static analysis techniques have been devised to find vulnerabilities in the source code. However, most of these techniques are built to encourage vulnerability detection a posteriori, only when developers have already fully produced (and compiled) one or more modules of a program. Therefore, this approach, also known as late detection, does not support secure programming but rather encourages posterior security analysis. The lateness of vulnerability detection is also influenced by the high rate of false positives, yielded by pattern matching, the underlying mechanism used by existing static analysis techniques. The goal of this paper is twofold. First, we propose to perform continuous detection of security vulnerabilities while the developer is editing each program statement, also known as early detection. Early detection can leverage his knowledge on the context of the code being created, contrary to late detection when developers struggle to recall and fix the intricacies of the vulnerable code they produced from hours to weeks ago. Second, we explore context-sensitive data flow analysis (DFA) for improving vulnerability detection and mitigate the limitations of pattern matching. DFA might be suitable for finding if an object has a vulnerable path. To this end, we have implemented a proof-of-concept Eclipse plugin for continuous DFA-based detection of vulnerabilities in Java programs. We also performed two empirical studies based on several industry-strength systems to evaluate if the code security can be improved through DFA and early vulnerability detection. Our studies confirmed that: (i) the use of context-sensitive DFA significantly reduces the rate of false positives when compared to existing techniques, without being detrimental to the detector performance, and (ii) early detection improves the awareness among developers and encourages programmers to fix security vulnerabilities promptly.},
  doi           = {10.1016/j.jss.2015.12.021},
  file          = {:article\\Exploring Context-Sensitive Data Flow Analysis for Early Vulnerability Detection.pdf:pdf},
  groups        = {imprortant},
  issn          = {01641212},
  keywords      = {Data flow analysis, Secure programming, Security vulnerability, early detection, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier Inc.},
  url           = {http://www.sciencedirect.com/science/article/pii/S0164121215002873},
}

@Book{Hafiz2015,
  title         = {{Game of detections: how are security vulnerabilities discovered in the wild?}},
  publisher     = {Empirical Software Engineering},
  year          = {2015},
  author        = {Hafiz, Munawar and Fang, Ming},
  __markedentry = {[ccc:6]},
  booktitle     = {Empirical Software Engineering},
  doi           = {10.1007/s10664-015-9403-7},
  file          = {:article\\Game of detections  how are security vulnerabilities discovered in the wild.pdf:PDF},
  groups        = {vice-important},
  isbn          = {1066401594},
  issn          = {15737616},
  keywords      = {Empirical study,Secure software engineering,Vulnerability,binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://dx.doi.org/10.1007/s10664-015-9403-7},
}

@Article{Muntean2015a,
  author        = {Muntean, Paul and Rabbi, Adnan and Ibing, Andreas and Eckert, Claudia},
  title         = {{Automated Detection of Information Flow Vulnerabilities in UML State Charts and C Code}},
  journal       = {Proceedings - 2015 IEEE International Conference on Software Quality, Reliability and Security-Companion, QRS-C 2015},
  year          = {2015},
  pages         = {128--137},
  __markedentry = {[ccc:6]},
  abstract      = {{\textcopyright} 2015 IEEE. Information flow vulnerabilities in UML statecharts and C code are detrimental as they can cause data leakagesor unexpected program behavior. Detecting such vulnerabilitieswith static code analysis techniques is challenging because codeis usually not available during the software design phase andprevious knowledge about what should be annotated and trackedis needed. In this paper we propose textual annotations used tointroduce information flow constraints in UML state charts andcode which are afterwards automatically loaded by informationflow checkers that check if imposed constraints hold or not. Weevaluated our approach on 6 open source test cases availablein the National Institute of Standards and Technology (NIST)Juliet test suite for C/C++. Our results show that our approachis effective and can be further applied to other types of UMLmodels and programming languages as well, in order to detectdifferent types of vulnerabilities.},
  doi           = {10.1109/QRS-C.2015.30},
  file          = {:article\\Automated Detection of Information Flow Vulnerabilities in UML State Charts and C Code.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9781467395984},
  keywords      = {Information flow vulnerability,Model-based verification,Static code analysis,first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  review        = {挖掘程序设计阶段的漏洞},
}

@Article{Shar2015,
  author        = {Shar, Lwin Khin and Briand, Lionel C. and Tan, Hee Beng Kuan},
  title         = {{Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning}},
  journal       = {IEEE Transactions on Dependable and Secure Computing},
  year          = {2015},
  volume        = {12},
  number        = {6},
  pages         = {688--707},
  __markedentry = {[ccc:6]},
  abstract      = {Due to limited time and resources, web software engineers need support in identifying vulnerable code. A practical approach to predicting vulnerable code would enable them to prioritize security auditing efforts. In this paper, we propose using a set of hybrid (static+dynamic) code attributes that characterize input validation and input sanitization code patterns and are expected to be significant indicators of web application vulnerabilities. Because static and dynamic program analyses complement each other, both techniques are used to extract the proposed attributes in an accurate and scalable way. Current vulnerability prediction techniques rely on the availability of data labeled with vulnerability information for training. For many real world applications, past vulnerability data is often not available or at least not complete. Hence, to address both situations where labeled past data is fully available or not, we apply both supervised and semi-supervised learning when building vulnerability predictors based on hybrid code attributes. Given that semi-supervised learning is entirely unexplored in this domain, we describe how to use this learning scheme effectively for vulnerability prediction. We performed empirical case studies on seven open source projects where we built and evaluated supervised and semi-supervised models. When cross validated with fully available labeled data, the supervised models achieve an average of 77 percent recall and 5 percent probability of false alarm for predicting SQL injection, cross site scripting, remote code execution and file inclusion vulnerabilities. With a low amount of labeled data, when compared to the supervised model, the semi-supervised model showed an average improvement of 24 percent higher recall and 3 percent lower probability of false alarm, thus suggesting semi-supervised learning may be a preferable solution for many real world applications where vulnerability data is missing.},
  doi           = {10.1109/TDSC.2014.2373377},
  file          = {:article\\Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning.pdf:pdf},
  groups        = {vice-important},
  issn          = {15455971},
  keywords      = {Vulnerability prediction,empirical study,first select,input validation and sanitization,machine learning,predicte,program analysis,second select,security measures,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Delaitre2015,
  author        = {Delaitre, Aurelien and Stivalet, Bertrand and Fong, Elizabeth and Okun, Vadim},
  title         = {{Evaluating bug finders - Test and measurement of static code analyzers}},
  journal       = {Proceedings - 1st International Workshop on Complex Faults and Failures in Large Software Systems, COUFLESS 2015},
  year          = {2015},
  pages         = {14--20},
  __markedentry = {[ccc:1]},
  abstract      = {—Software static analysis is one of many options for finding bugs in software. Like compilers, static analyzers take a program as input. This paper covers tools that examine source codewithout executing itand output bug reports. Static analysis is a complex and generally undecidable problem. Most tools resort to approximation to overcome these obstacles and it sometimes leads to incorrect results. Therefore, tool effectiveness needs to be evaluated. Several characteristics of the tools should be examined. First, what types of bugs can they find? Second, what proportion of bugs do they report? Third, what percentage of findings is correct? These questions can be answered by one or more metrics. But to calculate these, we need test cases having certain characteristics: statistical significance, ground truth, and relevance. Test cases with all three attributes are out of reach, but we can use combinations of only two to calculate the metrics. The results in this paper were collected during Static Analysis Tool Exposition (SATE) V, where participants ran 14 static analyzers on the test sets we provided and submitted their reports to us for analysis. Tools had considerably different support for most bug classes. Some tools discovered significantly more bugs than others or generated mostly accurate warnings, while others reported wrong findings more frequently. Using the metrics, an evaluator can compare candidates and select the tool that aligns best with his or her objectives. In addition, our results confirm that the bugs most commonly found by tools are among the most common and important bugs in software. We also observed that code complexity is a major hindrance for static analyzers and detailed which code constructs tools handle well and which impede their analysis.},
  doi           = {10.1109/COUFLESS.2015.10},
  file          = {:article\\Evaluating Bug Finders Test and Measurement of Static Code Analyzer.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781479919345},
  keywords      = {Software assurance, Software faults, Software vulnerability, Static analysis tools, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank1},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Shastry2015,
  author        = {Shastry, Bhargava and Yamaguchi, Fabian and Rieck, Konrad and Seifert, Jean-Pierre},
  title         = {{Towards Vulnerability Discovery Using Staged Program Analysis}},
  year          = {2015},
  pages         = {1--23},
  __markedentry = {[ccc:6]},
  abstract      = {Eliminating vulnerabilities from low-level code is vital for securing software. Static analysis is a promising approach for discovering vulnerabilities since it can provide developers early feedback on the code they write. But, it presents multiple challenges not the least of which is understanding what makes a bug exploitable and conveying this information to the developer. In this paper, we present the design and implementation of a practical vulnerability assessment framework, called Melange. Melange performs data and control flow analysis to diagnose potential security bugs, and outputs well-formatted bug reports that help developers understand and fix security bugs. Based on the intuition that real-world vulnerabilities manifest themselves across multiple parts of a program, Melange performs both local and global analyses. To scale up to large programs, global analysis is demand-driven. Our prototype detects multiple vulnerability classes in C and C++ code including type confusion, and garbage memory reads. We have evaluated Melange extensively. Our case studies show that Melange scales up to large codebases such as Chromium, is easy-to-use, and most importantly, capable of discovering vulnerabilities in real-world code. Our findings indicate that static analysis is a viable reinforcement to the software testing tool set.},
  archiveprefix = {arXiv},
  arxivid       = {1508.04627},
  eprint        = {1508.04627},
  groups        = {imprortant},
  keywords      = {binary,first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,web},
  url           = {http://arxiv.org/abs/1508.04627},
}

@Article{Gupta2015,
  author        = {Gupta, Mukesh Kumar and Govil, Mahesh Chandra and Singh, Girdhari},
  title         = {{Predicting Cross-Site Scripting (XSS) security vulnerabilities in web applications}},
  journal       = {Proceedings of the 2015 12th International Joint Conference on Computer Science and Software Engineering, JCSSE 2015},
  year          = {2015},
  pages         = {162--167},
  __markedentry = {[ccc:6]},
  abstract      = {Recently, machine-learning based vulnerability prediction models are gaining popularity in web security space, as these models provide a simple and efficient way to handle web application security issues. Existing state-of-art Cross-Site Scripting (XSS) vulnerability prediction approaches do not consider the context of the user-input in output-statement, which is very important to identify context-sensitive security vulnerabilities. In this paper, we propose a novel feature extraction algorithm to extract basic and context features from the source code of web applications. Our approach uses these features to build various machine-learning models for predicting context-sensitive Cross-Site Scripting (XSS) security vulnerabilities. Experimental results show that the proposed features based prediction models can discriminate vulnerable code from non-vulnerable code at a very low false rate.},
  doi           = {10.1109/JCSSE.2015.7219789},
  file          = {:article\\Predicting Cross-Site Scripting (XSS) security vulnerabilities in web applications.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9781479919659},
  keywords      = {context-sensitive,cross-site scripting vulnerability,first select,input validation,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web,web application security},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Bahamdain2015,
  author        = {Bahamdain, Salem S.},
  title         = {{Open source software (OSS) quality assurance: A survey paper}},
  journal       = {Procedia Computer Science},
  year          = {2015},
  volume        = {56},
  number        = {1},
  pages         = {459--464},
  __markedentry = {[ccc:6]},
  abstract      = {Open source software (OSS) is a software product with the source code made public so that anyone can read, analyze, and change or improve the code. The use of this software is under a license, like Apache, GNU, MIT, Mozilla Public, and Eclipse Public License. Open source software development (OSSD) provides high quality assurance through user testing and peer reviews. The quality of these products depends on the size of the product community. This paper discusses the stakeholders of the OSS community, the quality assurance frameworks and models proposed in some studies, some statistics about OSS, the problems that affect the quality of OSSD, and the advantages and disadvantages of OSS compared to closed source software. This allows us to understand how we can achieve and improve the quality assurance and quality control of OSSD.},
  doi           = {10.1016/j.procs.2015.07.236},
  file          = {:article\\Open Source Software (OSS) Quality Assurance A Survey Paper.pdf:PDF},
  groups        = {vice-important},
  isbn          = {0-7695-2977-1},
  issn          = {18770509},
  keywords      = {OSS, open source,OSSD,Open source development model,Quality assurance,first select,second select,source code,source code-important,source code-vice important,survey,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,survey,web},
  pmid          = {21444166},
  publisher     = {Elsevier Masson SAS},
  url           = {http://dx.doi.org/10.1016/j.procs.2015.07.236},
}

@Article{Hydara2015,
  author        = {Hydara, Isatou and Sultan, Abu Bakar Md and Zulzalil, Hazura and Admodisastro, Novia},
  title         = {{Current state of research on cross-site scripting (XSS) - A systematic literature review}},
  journal       = {Information and Software Technology},
  year          = {2015},
  volume        = {58},
  pages         = {170--186},
  __markedentry = {[ccc:6]},
  abstract      = {Context: Cross-site scripting (XSS) is a security vulnerability that affects web applications. It occurs due to improper or lack of sanitization of user inputs. The security vulnerability caused many problems for users and server applications. Objective: To conduct a systematic literature review on the studies done on XSS vulnerabilities and attacks. Method: We followed the standard guidelines for systematic literature review as documented by Barbara Kitchenham and reviewed a total of 115 studies related to cross-site scripting from various journals and conference proceedings. Results: Research on XSS is still very active with publications across many conference proceedings and journals. Attack prevention and vulnerability detection are the areas focused on by most of the studies. Dynamic analysis techniques form the majority among the solutions proposed by the various studies. The type of XSS addressed the most is reflected XSS. Conclusion: XSS still remains a big problem for web applications, despite the bulk of solutions provided so far. There is no single solution that can effectively mitigate XSS attacks. More research is needed in the area of vulnerability removal from the source code of the applications before deployment.},
  doi           = {10.1016/j.infsof.2014.07.010},
  file          = {:article\\A systematic literature review.pdf:pdf},
  groups        = {vice-important},
  issn          = {09505849},
  keywords      = {Cross-site scripting,Security,Systematic literature review,Web applications,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,survey,web},
  mendeley-tags = {first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,survey,web},
  publisher     = {Elsevier B.V.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2014.07.010},
}

@Article{Catherine2015,
  author        = {Catherine, S. Monica and George, Geogen},
  title         = {{S-compiler: A code vulnerability detection method}},
  journal       = {International Conference on Electrical, Electronics, Signals, Communication and Optimization, EESCO 2015},
  year          = {2015},
  pages         = {2--5},
  __markedentry = {[ccc:3]},
  abstract      = {Nowadays, security breaches are greatly increasing in number. This is one of the major threats that are being faced by most organisations which usually lead to a massive loss. The major cause for these breaches could potentially be the vulnerabilities in software products. There are many tools available to detect such vulnerabilities but detection and correction of vulnerabilities during development phase would be more beneficial. Though there are many standard secure coding practices to be followed in development phase, software developers fail to utilize them and this leads to an unsecured end product. The difficulty in manual analysis of vulnerabilities in source code is what leads to the evolution of automated analysis tools. Static and dynamic analyses are the two complementary methods used to detect vulnerabilities in development phase. Static analysis scans the source code which eliminates the need of execution of the code but it has many false positives and false negatives. On the other hand, dynamic analysis tests the code by running it along with the test cases. The proposed approach integrates static and dynamic analysis. This eliminates the false positives and false negatives problem of the existing practices and helps developers to correct their code in the most efficient way. It deals with common buffer overflow vulnerabilities and vulnerabilities from Common Weakness Enumeration (CWE). The whole scenario is implemented as a web interface.},
  doi           = {10.1109/EESCO.2015.7254018},
  file          = {:article\\S-COMPILER_A CODE VULNERABILITY DETECTION METHOD.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781479976768},
  keywords      = {Buffer overflow, Dynamic analysis, Secure coding, Static analysis, first select, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank3},
  mendeley-tags = {first select,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Yamaguchi2015,
  author        = {Yamaguchi, Fabian and Maier, Alwin and Gascon, Hugo and Rieck, Konrad},
  title         = {{Automatic inference of search patterns for taint-style vulnerabilities}},
  journal       = {Proceedings - IEEE Symposium on Security and Privacy},
  year          = {2015},
  volume        = {2015-July},
  pages         = {797--812},
  __markedentry = {[ccc:5]},
  abstract      = {Taint-style vulnerabilities are a persistent problem in software development, as the recently discovered “Heartbleed” vulnerability strikingly illustrates. In this class of vulnerabil- ities, attacker-controlled data is passed unsanitized from an input source to a sensitive sink. While simple instances of this vulnerability class can be detected automatically, more subtle defects involving data flow across several functions or project- specific APIs are mainly discovered by manual auditing. Different techniques have been proposed to accelerate this process by searching for typical patterns of vulnerable code. However, all of these approaches require a security expert to manually model and specify appropriate patterns in practice. In this paper, we propose a method for automatically inferring search patterns for taint-style vulnerabilities in C code. Given a security-sensitive sink, such as a memory function, our method automatically identifies corresponding source-sink systems and constructs patterns that model the data flow and sanitization in these systems. The inferred patterns are expressed as traversals in a code property graph and enable efficiently searching for unsanitized data flows—across several functions as well as with project-specific APIs. We demonstrate the efficacy of this approach in different experiments with 5 open-source projects. The inferred search patterns reduce the amount of code to inspect for finding known vulnerabilities by 94.9{\%} and also enable us to uncover 8 previously unknown vulnerabilities.},
  doi           = {10.1109/SP.2015.54},
  file          = {:article\\Automatic inference of search patterns for taint-style vulnerabilities.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781467369497},
  issn          = {10816011},
  keywords      = {Clustering, Graph Databases, Vulnerabilities, binary, first select, fuzz, machine learning, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {binary,first select,fuzz,machine learning,second select,source code,source code-important,source code-vice important,web},
}

@Article{Mokhov2015,
  author        = {Mokhov, Serguei A. and Paquet, Joey and Debbabi, Mourad},
  title         = {{MARFCAT : Fast Code Analysis for Defects and Vulnerabilities}},
  journal       = {Proceedings of the 1st International Workshop on Software Analytics (SWAN)},
  year          = {2015},
  pages         = {35--38},
  __markedentry = {[ccc:3]},
  doi           = {10.1109/SWAN.2015.7070488},
  file          = {:article\\MARFCAT_Fast Code Analysis for Defects and Vulnerabilities.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781467369237},
  keywords      = {binary, first select, fuzz, machine learning, marfcat, predicte, second select, signal processing, source code, source code-important, source code-vice important, stat, static analysi, static analysis, static code analysis, web, rank3},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Gosain2015,
  author        = {Gosain, Anjana and Sharma, Ganga},
  title         = {{Static Analysis: A Survey of Techniques and Tools}},
  journal       = {Advances in Intelligent Systems and Computing},
  year          = {2015},
  __markedentry = {[ccc:5]},
  abstract      = {Static program analysis has shown tremendous surge from basic compiler optimization technique to becoming a major role player in correctness and verification of software. Because of its rich theoretical background, static analysis is in a good position to help produce quality software. This paper provides an overview of the existing static analysis techniques and tools. Further, it gives a critique of static analysis approach over six attributes, namely precision, efficiency, coverage, modularity, scalability, and automation.},
  doi           = {10.1007/978-81-322-2268-2},
  file          = {:article\\Static Analysis_A Survey of Techniques and Tools.pdf:PDF},
  groups        = {imprortant},
  isbn          = {978-81-322-2267-5},
  issn          = {21945357},
  keywords      = {Feature selection, Machine learning, Movie domain, Sentiment analysis, Sentiment classification, first select, machine learning, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {first select,machine learning,second select,source code,source code-important,source code-vice important,web},
  url           = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84924058158{\&}partnerID=tZOtx3y1},
}

@Article{Shar2015a,
  author        = {Shar, Lwin Khin and Briand, Lionel C and Tan, Hee Kuan and Member, Senior},
  title         = {{Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning}},
  journal       = {IEEE Transactions on Dependable and Secure Computing},
  year          = {2015},
  volume        = {12},
  number        = {6},
  pages         = {688--707},
  __markedentry = {[ccc:6]},
  abstract      = {Due to limited time and resources, web software engineers need support in identifying vulnerable code. A practical approach to predicting vulnerable code would enable them to prioritize security auditing efforts. In this paper, we propose using a set of hybrid (staticþdynamic) code attributes that characterize input validation and input sanitization code patterns and are expected to be significant indicators of web application vulnerabilities. Because static and dynamic program analyses complement each other, both techniques are used to extract the proposed attributes in an accurate and scalable way. Current vulnerability prediction techniques rely on the availability of data labeled with vulnerability information for training. For many real world applications, past vulnerability data is often not available or at least not complete. Hence, to address both situations where labeled past data is fully available or not, we apply both supervised and semi-supervised learning when building vulnerability predictors based on hybrid code attributes. Given that semi-supervised learning is entirely unexplored in this domain, we describe how to use this learning scheme effectively for vulnerability prediction. We performed empirical case studies on seven open source projects where we built and evaluated supervised and semi-supervised models. When cross validated with fully available labeled data, the supervised models achieve an average of 77 percent recall and 5 percent probability of false alarm for predicting SQL injection, cross site scripting, remote code execution and file inclusion vulnerabilities. With a low amount of labeled data, when compared to the supervised model, the semi-supervised model showed an average improvement of 24 percent higher recall and 3 percent lower probability of false alarm, thus suggesting semi-supervised learning may be a preferable solution for many real world applications where vulnerability data is missing},
  file          = {:article\\Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning.pdf:pdf},
  groups        = {vice-important},
  keywords      = {Vulnerability prediction,empirical study,first select,input validation and sanitization,machine learning,predicte,program analysis,second select,security measures,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Tang2015,
  author        = {Tang, Yaming and Zhao, Fei and Yang, Yibiao and Lu, Hongmin and Zhou, Yuming and Xu, Baowen},
  title         = {{Predicting Vulnerable Components via Text Mining or Software Metrics? An Effort-Aware Perspective}},
  journal       = {2015 IEEE International Conference on Software Quality, Reliability and Security},
  year          = {2015},
  pages         = {27--36},
  __markedentry = {[ccc:6]},
  doi           = {10.1109/QRS.2015.15},
  file          = {:article\\Predicting Vulnerable Components via Text Mining or Software Metrics An Effort-Aware Perspective.pdf:pdf},
  groups        = {vice-important},
  isbn          = {978-1-4673-7989-2},
  keywords      = {-software metrics,binary,effort-aware,first select,machine learning,predicte,prediction,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7272911},
}

@Article{Pan2015,
  author        = {Pan, Jinkun and Mao, Xiaoguang and Li, Weishi},
  title         = {{Analyst-oriented taint analysis by taint path slicing and aggregation}},
  journal       = {Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS},
  year          = {2015},
  volume        = {2015-Novem},
  pages         = {145--148},
  __markedentry = {[ccc:6]},
  doi           = {10.1109/ICSESS.2015.7339024},
  file          = {:article\\Analyst-oriented taint analysis by taint path slicing and aggregation.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9781479983520},
  issn          = {23270594},
  keywords      = {analyst,first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,taint analysis,taint path,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Sidiroglou-douskos2015,
  author        = {Sidiroglou-douskos, Stelios and Lahtinen, Eric and Rinard, Martin and Sidiroglou-douskos, Stelios and Lahtinen, Eric and Rinard, Martin},
  title         = {{Automatic Discovery and Patching of Buffer and Integer Overflow Errors}},
  year          = {2015},
  __markedentry = {[ccc:4]},
  file          = {:article\\Automatic Discovery and Patching of Buffer and Integer Overflow Errors MIT-CSAIL-TR-2015-018.pdf:PDF},
  groups        = {imprortant},
  keywords      = {binary, first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {binary,first select,fuzz,second select,source code,source code-important,source code-vice important,web},
}

@Article{He2015,
  author        = {He, Boyuan and Rastogi, Vaibhav and Cao, Yinzhi and Chen, Yan and Venkatakrishnan, V. N. and Yang, Runqing and Zhang, Zhenrui},
  title         = {{Vetting SSL usage in applications with SSLINT}},
  journal       = {Proceedings - IEEE Symposium on Security and Privacy},
  year          = {2015},
  volume        = {2015-July},
  pages         = {519--534},
  __markedentry = {[ccc:4]},
  abstract      = {Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols have become the security backbone of the Web and Internet today. Many systems including mobile and desktop applications are protected by SSL/TLS protocols against network attacks. However, many vulnerabilities caused by incorrect use of SSL/TLS APIs have been uncovered in recent years. Such vulnerabilities, many of which are caused due to poor API design and inexperience of application developers, often lead to confidential data leakage or man-in-the-middle attacks. In this paper, to guarantee code quality and logic correctness of SSL/TLS applications, we design and implement SSLINT, a scalable, automated, static analysis system for detecting incorrect use of SSL/TLS APIs. SSLINT is capable of performing automatic logic verification with high efficiency and good accuracy. To demonstrate it, we apply SSLINT to one of the most popular Linux distributions -- Ubuntu. We find 27 previously unknown SSL/TLS vulnerabilities in Ubuntu applications, most of which are also distributed with other Linux distributions.},
  doi           = {10.1109/SP.2015.38},
  file          = {:article\\Vetting SSL usage in applications with SSLINT.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781467369497},
  issn          = {10816011},
  keywords      = {first select, fuzz, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank4},
  mendeley-tags = {first select,fuzz,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Goseva-Popstojanova2015,
  author        = {Goseva-Popstojanova, Katerina and Perhinschi, Andrei},
  title         = {{On the capability of static code analysis to detect security vulnerabilities}},
  journal       = {Information and Software Technology},
  year          = {2015},
  volume        = {68},
  pages         = {18--33},
  __markedentry = {[ccc:3]},
  abstract      = {Context: Static analysis of source code is a scalable method for discovery of software faults and security vulnerabilities. Techniques for static code analysis have matured in the last decade and many tools have been developed to support automatic detection. Objective: This research work is focused on empirical evaluation of the ability of static code analysis tools to detect security vulnerabilities with an objective to better understand their strengths and shortcomings. Method: We conducted an experiment which consisted of using the benchmarking test suite Juliet to evaluate three widely used commercial tools for static code analysis. Using design of experiments approach to conduct the analysis and evaluation and including statistical testing of the results are unique characteristics of this work. In addition to the controlled experiment, the empirical evaluation included case studies based on three open source programs. Results: Our experiment showed that 27{\%} of C/C++ vulnerabilities and 11{\%} of Java vulnerabilities were missed by all three tools. Some vulnerabilities were detected by only one or combination of two tools; 41{\%} of C/C++ and 21{\%} of Java vulnerabilities were detected by all three tools. More importantly, static code analysis tools did not show statistically significant difference in their ability to detect security vulnerabilities for both C/C++ and Java. Interestingly, all tools had median and mean of the per CWE recall values and overall recall across all CWEs close to or below 50{\%}, which indicates comparable or worse performance than random guessing. While for C/C++ vulnerabilities one of the tools had better performance in terms of probability of false alarm than the other two tools, there was no statistically significant difference among tools' probability of false alarm for Java test cases. Conclusions: Despite recent advances in methods for static code analysis, the state-of-the-art tools are not very effective in detecting security vulnerabilities.},
  doi           = {10.1016/j.infsof.2015.08.002},
  file          = {:article\\On the capability of static code analysis to detect security vulnerabilities.pdf:pdf},
  groups        = {imprortant},
  issn          = {09505849},
  keywords      = {Case studies, Common Weakness Enumeration (CWE), Experiment, Security vulnerabilities, Static code analysis evaluation, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank3},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Elsevier Ltd.},
  url           = {http://dx.doi.org/10.1016/j.infsof.2015.08.002},
}

@Article{Perl2015,
  author        = {Perl, Henning and Smith, Matthew and Arp, Daniel and Yamaguchi, Fabian and Rieck, Konrad and Fahl, Sascha},
  title         = {{VCCFinder : Finding Potential Vulnerabilities in Open-Source Projects to Assist Code}},
  journal       = {Ccs '15},
  year          = {2015},
  pages         = {426--437},
  __markedentry = {[ccc:2]},
  abstract      = {Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. How-ever, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag poten-tially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding poten-tially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We com-bine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 {\%} at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service.},
  doi           = {10.1145/2810103.2813604},
  file          = {:article\\VCCFinder Finding Potential Vulnerabilities in Open-Source Projects to Assist Code.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781450338325},
  issn          = {15437221},
  keywords      = {binary, first select, fuzz, machine learning, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, vulnerabilities, web, rank2},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Cook2015,
  author        = {Cook, D and Choe, Y R and {Hamilton Jr}, J A},
  title         = {{Finding bugs in source code using commonly available development metadata}},
  journal       = {Workshop on Cyber Security Experiment and Test},
  year          = {2015},
  __markedentry = {[ccc:6]},
  abstract      = {Developers and security analysts have been using static analysis for a long time to analyze programs for defects and vulnerabilities. Generally a static analysis tool is run on the source code for a given program, flagging areas of code that need to be further inspected by a human an- alyst. These tools tend to work fairly well – every year they find many important bugs. These tools are more impressive considering the fact that they only examine the source code, which may be very complex. Now con- sider the amount of data available that these tools do not analyze. There are many additional pieces of informa- tion available that would prove useful for finding bugs in code, such as a history of bug reports, a history of all changes to the code, information about committers, etc. By leveraging all this additional data, it is possible to find more bugs with less user interaction, as well as track useful metrics such as number and type of defects injected by committer. This paper provides a method for leveraging development metadata to find bugs that would otherwise be difficult to find using standard static analy- sis tools. We showcase two case studies that demonstrate the ability to find new vulnerabilities in large and small software projects by finding new vulnerabilities in the cpython and Roundup open source projects.},
  file          = {:article\\Finding Bugs in Source Code Using Commonly Available Development.pdf:PDF},
  groups        = {vice-important},
  keywords      = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
  url           = {https://www.usenix.org/conference/cset15/workshop-program/presentation/cook$\backslash$npapers3://publication/uuid/08AEBA4B-48AA-4D4A-ABE7-267304976AD3},
}

@Article{Yamaguchi2015a,
  author        = {Yamaguchi, Fabian},
  title         = {{Pattern-Based Vulnerability Discovery}},
  year          = {2015},
  __markedentry = {[ccc:5]},
  file          = {:article\\Pattern-Based Vulnerability Discovery.pdf:pdf},
  groups        = {imprortant},
  keywords      = {first select, fuzz, machine learning, predicte, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{He2015a,
  author        = {He, Peng and Li, Bing and Liu, Xiao and Chen, Jun and Ma, Yutao},
  title         = {{An empirical study on software defect prediction with a simplified metric set}},
  journal       = {Information and Software Technology},
  year          = {2015},
  volume        = {59},
  pages         = {170--190},
  __markedentry = {[ccc:6]},
  abstract      = {Context Software defect prediction plays a crucial role in estimating the most defect-prone components of software, and a large number of studies have pursued improving prediction accuracy within a project or across projects. However, the rules for making an appropriate decision between within- and cross-project defect prediction when available historical data are insufficient remain unclear. Objective The objective of this work is to validate the feasibility of the predictor built with a simplified metric set for software defect prediction in different scenarios, and to investigate practical guidelines for the choice of training data, classifier and metric subset of a given project. Method First, based on six typical classifiers, three types of predictors using the size of software metric set were constructed in three scenarios. Then, we validated the acceptable performance of the predictor based on Top-k metrics in terms of statistical methods. Finally, we attempted to minimize the Top-k metric subset by removing redundant metrics, and we tested the stability of such a minimum metric subset with one-way ANOVA tests. Results The study has been conducted on 34 releases of 10 open-source projects available at the PROMISE repository. The findings indicate that the predictors built with either Top-k metrics or the minimum metric subset can provide an acceptable result compared with benchmark predictors. The guideline for choosing a suitable simplified metric set in different scenarios is presented in Table 12. Conclusion The experimental results indicate that (1) the choice of training data for defect prediction should depend on the specific requirement of accuracy; (2) the predictor built with a simplified metric set works well and is very useful in case limited resources are supplied; (3) simple classifiers (e.g., Na{\"{i}}ve Bayes) also tend to perform well when using a simplified metric set for defect prediction; and (4) in several cases, the minimum metric subset can be identified to facilitate the procedure of general defect prediction with acceptable loss of prediction precision in practice.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1402.3873v2},
  doi           = {10.1016/j.infsof.2014.11.006},
  eprint        = {arXiv:1402.3873v2},
  file          = {:article\\An empirical study on software defect prediction with a simplified metric set.pdf:pdf},
  groups        = {vice-important},
  isbn          = {9789881925237},
  issn          = {09505849},
  keywords      = {Defect prediction,Metric set simplification,Software metrics,Software quality,binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important},
}

@Article{Yeh2015b,
  author        = {Yeh, Chao-Chun and Chung, Hsiang and Huang, Shih-Kun},
  title         = {{CRAXfuzz: Target-Aware Symbolic Fuzz Testing}},
  journal       = {2015 IEEE 39th Annual Computer Software and Applications Conference},
  year          = {2015},
  pages         = {460--471},
  __markedentry = {[ccc:6]},
  doi           = {10.1109/COMPSAC.2015.99},
  groups        = {vice-important},
  isbn          = {978-1-4673-6564-2},
  issn          = {07303157},
  keywords      = {-component,fuzz testing,software testing,source code,source code-important,symbolic execution,vulnerability},
  mendeley-tags = {source code,source code-important},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7273654},
}

@Article{Liang2016,
  author        = {Liang, Bin and Bian, Pan and Zhang, Yan and Shi, Wenchang and You, Wei},
  title         = {{AntMiner : Mining More Bugs by Reducing Noise Interference}},
  journal       = {Icse},
  year          = {2016},
  __markedentry = {[ccc:5]},
  abstract      = {Detecting bugs with code mining has proven to be an effective approach. However, the existing methods suffer from reporting serious false positives and false negatives. In this paper, we de- veloped an approach called AntMiner to improve the precision of code mining by carefully preprocessing the source code. Specifi- cally, we employ the program slicing technique to decompose the original source repository into independent sub-repositories, tak- ing critical operations (automatically extracted from source code) as slicing criteria. In this way, the statements irrelevant to a criti- cal operation are excluded from the corresponding sub-repository. Besides, various semantics-equivalent representations are normal- ized into a canonical form. Eventually, the mining process can be performed on a refined code database, and false positives and false negatives can be significantly pruned. We have implemented AntMiner and applied it to detect bugs in the Linux kernel. It re- ported 52 violations that have been either confirmed as real bugs by the kernel development community or fixed in new kernel versions. Among them, 41 cannot be detected by a widely used representative analysis tool Coverity. Besides, the result of a com- parative analysis shows that our approach can effectively improve the precision of code mining and detect subtle bugs that have previously been missed. CCS},
  doi           = {10.1145/2884781.2884870},
  file          = {:article\\AntMiner_mining more bugs by reducing noise interference.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781450339001},
  keywords      = {bug detection, code mining, first select, program slicing, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@InProceedings{Li2016,
  author        = {Li, Hongzhe and Oh, Jaesang and Oh, Hakjoo and Lee, Heejo},
  title         = {{Automated Source Code Instrumentation for Verifying Potential Vulnerabilities}},
  booktitle     = {IFIP International Federation for Information Processing 2016},
  year          = {2016},
  pages         = {211--226},
  __markedentry = {[ccc:5]},
  abstract      = {With a rapid yearly growth rate, software vulnerabilities are making great threats to the system safety. In theory, detecting and removing vulnerabilities before the code gets ever deployed can greatly ensure the quality of software released. However, due to the enormous amount of code being developed as well as the lack of human resource and expertise, severe vulnerabilities still remain concealed or cannot be revealed effectively. Current source code auditing tools for vulnerability discovery either generate too many false positives or require overwhelming manual efforts to report actual software flaws. In this paper, we propose an automatic verification mechanism to discover and verify vulnerabilities by using program source instrumentation and concolic testing. In the beginning, we leverage CIL to statically analyze the source code including extracting the program CFG, locating the security sinks and backward tracing the sensitive variables. Subsequently, we perform automated program instrumentation to insert security probes ready for the vulnerability verification. Finally, the instrumented program source is passed to the concolic testing engine to verify and report the existence of an actual vulnerability. We demonstrate the efficacy and efficiency of our mechanism by implementing a prototype system and perform experiments with nearly 4000 test cases from Juliet Test Suite. The results show that our system can verify over 90 {\%} of test cases and it reports buffer overflow flaws with P recision = 100 {\%} (0 FP) and Recall = 94.91 {\%}. In order to prove the practicability of our system working in real world programs, we also apply our system on 2 popular Linux utilities, Bash and Cpio. As a result, our system finds and verifies vulnerabilities in a fully automatic way with no false positives.},
  doi           = {10.1007/978-3-319-18467-8},
  file          = {:article\\Automated Source Code Instrumentation for Verifying Potential Vulnerabilities.pdf:pdf},
  groups        = {imprortant},
  isbn          = {978-3-319-18466-1},
  issn          = {18684238},
  keywords      = {Employee security behavior, National culture, Organisational culture, Security countermeasures, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84942582480{\&}partnerID=tZOtx3y1},
}

@InProceedings{Yun2016,
  author        = {Yun, Insu and Min, Changwoo and Si, Xujie and Jang, Yeongjin and Kim, Taesoo and Naik, Mayur},
  title         = {{APIS an : Sanitizing API Usages through Semantic Cross-Checking}},
  booktitle     = {Proceedings - 2016 25th USENIX Security Symposium},
  year          = {2016},
  __markedentry = {[ccc:5]},
  abstract      = {API misuse is a well-known source of bugs. Some of them (e.g., incorrect use of SSL API, and integer overflow of memory allocation size) can cause serious security vulnerabilities (e.g., man-in-the-middle (MITM) attack, and privilege escalation). Moreover, modern APIs, which are large, complex, and fast evolving, are error-prone. However, existing techniques to help finding bugs require manual effort by developers (e.g., providing specification or model) or are not scalable to large real-world software comprising millions of lines of code. In this paper, we present APISAN, a tool that automat- ically infers correct API usages from source code without manual effort. The key idea in APISAN is to extract likely correct usage patterns in four different aspects (e.g., causal relation, and semantic relation on arguments) by considering semantic constraints. APISAN is tailored to check various properties with security implications. We applied APISAN to 92 million lines of code, includ- ing Linux Kernel, and OpenSSL, found 76 previously unknown bugs, and provided patches for all the bugs. 1},
  file          = {:article\\APISan_Sanitizing API Usages through.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781931971324},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Yan2016,
  author        = {Yan, Hua},
  title         = {{Automated Memory Leak Fixing on Value-Flow Slices for C Programs}},
  year          = {2016},
  pages         = {1386--1393},
  __markedentry = {[ccc:5]},
  file          = {:article\\Automated Memory Leak Fixing on Value-Flow Slices for C Programs.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781450337397},
  keywords      = {first select, second select, source code, source code-important, source code-vice important, rank5},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Wang2016,
  author        = {Wang, Song and Chollak, Devin and Movshovitz-Attias, Dana and Tan, Lin},
  title         = {{Bugram: bug detection with n-gram language models}},
  journal       = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering - ASE 2016},
  year          = {2016},
  pages         = {708--719},
  __markedentry = {[ccc:4]},
  abstract      = {To improve software reliability, many rule-based techniques have been proposed to infer programming rules and detect violations of these rules as bugs. These rule-based approaches often rely on the highly frequent appearances of certain patterns in a project to infer rules. It is known that if a pattern does not appear frequently enough, rules are not learned, thus missing many bugs. In this paper, we propose a new approach—Bugram—that lever-ages n-gram language models instead of rules to detect bugs. Bu-gram models program tokens sequentially, using the n-gram lan-guage model. Token sequences from the program are then assessed according to their probability in the learned model, and low prob-ability sequences are marked as potential bugs. The assumption is that low probability token sequences in a program are unusual, which may indicate bugs, bad practices, or unusual/special uses of code of which developers may want to be aware. We evaluate Bugram in two ways. First, we apply Bugram on the latest versions of 16 open source Java projects. Results show that Bugram detects 59 bugs, 42 of which are manually verified as cor-rect, 25 of which are true bugs and 17 are code snippets that should be refactored. Among the 25 true bugs, 23 cannot be detected by PR-Miner. We have reported these bugs to developers, 7 of which have already been confirmed by developers (4 of them have already been fixed), while the rest await confirmation. Second, we further compare Bugram with three additional graph-and rule-based bug detection tools, i.e., JADET, Tikanga, and GrouMiner. We apply Bugram on 14 Java projects evaluated in these three studies. Bu-gram detects 21 true bugs, at least 10 of which cannot be detected by these three tools. Our results suggest that Bugram is comple-mentary to existing rule-based bug detection approaches.},
  doi           = {10.1145/2970276.2970341},
  file          = {:article\\Bugram_Bug Detection with N-gram Language Models.pdf:PDF},
  groups        = {imprortant},
  isbn          = {9781450338455},
  keywords      = {Keywords Bug Detection, N-gram Language Model, Software testing and debugging, Static Code Analysis, first select, second select, source code, source code-important, source code-vice important, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
  url           = {http://dl.acm.org/citation.cfm?doid=2970276.2970341},
}

@Article{Younis2016,
  author        = {Younis, Awad and {Yashwant Malaiya} and Anderson, Charles and Ray, Indrajit},
  title         = {{To Fear or Not to Fear That is the Question: Code Characteristics of a Vulnerable Function with an Existing Exploit}},
  journal       = {Proceedings of the ACM Conference on Data and Application Security and Privacy (CODASPY)},
  year          = {2016},
  pages         = {97--104},
  __markedentry = {[ccc:6]},
  doi           = {10.1145/2857705.2857750},
  file          = {:article\\To Fear or Not to Fear That is the Question_Code Characteristics of a Vulnerable Functionwith an Existing Exploit.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9781450339353},
  keywords      = {binary, data mining and machine, exploitability, exploits, feature selection, first select, fuzz, learning, machine learning, predicte, prediction, second select, software metrics, software security, source code, source code-important, source code-vice important, stat, static analysi, static analysis, vulnerabilities severity, web, rank5},
  mendeley-tags = {binary,first select,fuzz,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Ray2016,
  author        = {Ray, Baishakhi and Bacchelli, Alberto},
  title         = {{On the “ Naturalness ” of Buggy Code}},
  year          = {2016},
  __markedentry = {[ccc:6]},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1506.01159v2},
  eprint        = {arXiv:1506.01159v2},
  file          = {:article\\On the Naturalness of buggy code.pdf:PDF},
  groups        = {vice-important},
  isbn          = {9781450339001},
  keywords      = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Kim2016,
  author        = {Kim, Joon-Ho and Ma, Myung-Chul and Park, Jae-Pyo},
  title         = {{An analysis on secure coding using symbolic execution engine}},
  journal       = {Journal of Computer Virology and Hacking Techniques},
  year          = {2016},
  volume        = {12},
  number        = {3},
  pages         = {177--184},
  __markedentry = {[ccc:5]},
  doi           = {10.1007/s11416-016-0263-5},
  file          = {:article\\An analysis on secure coding using symbolic execution engine.pdf:pdf},
  groups        = {imprortant},
  issn          = {2263-8733},
  keywords      = {first select, fuzz, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, web, rank5},
  mendeley-tags = {first select,fuzz,second select,source code,source code-important,source code-vice important,web},
  publisher     = {Springer Paris},
  url           = {http://link.springer.com/10.1007/s11416-016-0263-5},
}

@Article{Medeiros2016,
  author        = {Medeiros, Iberia and Neves, Nuno and Correia, Miguel},
  title         = {{Detecting and Removing Web Application Vulnerabilities with Static Analysis and Data Mining}},
  journal       = {IEEE Transactions on Reliability},
  year          = {2016},
  volume        = {65},
  number        = {1},
  pages         = {54--69},
  __markedentry = {[ccc:6]},
  abstract      = {Although a large research effort on web application security has been going on for more than a decade, the security of web applications continues to be a challenging problem. An important part of that problem derives from vulnerable source code, often written in unsafe languages like PHP. Source code static analysis tools are a solution to find vulnerabilities, but they tend to generate false positives, and require considerable effort for programmers to manually fix the code. We explore the use of a combination of methods to discover vulnerabilities in source code with fewer false positives. We combine taint analysis, which finds candidate vulnerabilities, with data mining, to predict the existence of false positives. This approach brings together two approaches that are apparently orthogonal: humans coding the knowledge about vulnerabilities (for taint analysis), joined with the seemingly orthogonal approach of automatically obtaining that knowledge (with machine learning, for data mining). Given this enhanced form of detection, we propose doing automatic code correction by inserting fixes in the source code. Our approach was implemented in the WAP tool, and an experimental evaluation was performed with a large set of PHP applications. Our tool found 388 vulnerabilities in 1.4 million lines of code. Its accuracy and precision were approximately 5{\%} better than PhpMinerII's and 45{\%} better than Pixy's.},
  doi           = {10.1109/TR.2015.2457411},
  file          = {:article\\Detecting and Removing Web Application Vulnerabilities with Static Analysis and Data Mining.pdf:pdf},
  groups        = {vice-important},
  issn          = {00189529},
  keywords      = {Automatic protection,binary,data mining,false positives,first select,input validation vulnerabilities,machine learning,predicte,second select,software security,source code,source code static analysis,source code-important,source code-vice important,stat,static analysi,static analysis,web,web applications},
  mendeley-tags = {binary,first select,machine learning,predicte,second select,source code,source code-important,source code-vice important,web},
}

@Article{Lingzi2016,
  author        = {Lingzi, Xiang and Zhi, Lin},
  title         = {{An Overview of Source Code Audit}},
  journal       = {Proceedings - 2015 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration, ICIICII 2015},
  year          = {2016},
  pages         = {26--29},
  __markedentry = {[ccc:4]},
  doi           = {10.1109/ICIICII.2015.94},
  file          = {:article\\An Overview of Source Code Audit.pdf:pdf},
  groups        = {imprortant},
  isbn          = {9781467383127},
  keywords      = {first select, information security, source code, source code review, source code-important, source code-vice important, stat, static analysi, static analysis, survey, web, rank4},
  mendeley-tags = {first select,source code,source code-important,source code-vice important,survey,web},
}

@Misc{Paul,
  author        = {Paul, Santanu},
  title         = {{A Framework for Source Code Search using Program Patterns 2 Comparison with Other Tools}},
  year          = {1994},
  __markedentry = {[ccc:4]},
  file          = {:article\\A framework for source code search using program patterns （CR 135）.pdf:PDF},
  groups        = {imprortant},
  keywords      = {first select, ing, pattern match-, program understanding, query language, reverse engineering, second select, software maintenance, software reengineering, source code, source code-important, source code-vice important, rank4},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important},
}

@Article{Lechtaler,
  author        = {Lechtaler, Antonio Castro and Liporace, Julio C{\'{e}}sar and Cipriano, Marcelo and Maiorano, Ariel and Malvacio, Eduardo and Tapia, N{\'{e}}stor},
  title         = {{Automated Analysis of Source Code Patches using Machine Learning Algorithms}},
  number        = {January 2011},
  __markedentry = {[ccc:3]},
  file          = {:article\\Automated Analysis of Source Code Patches using Machine Learning Algorithms.pdf:pdf},
  groups        = {imprortant},
  keywords      = {analysis, automated, binary, first select, machine learning, patch, second select, software quality, source code, source code analysis, source code review, source code-important, source code-vice important, stat, static analysi, static analysis, text mining, web, rank3},
  mendeley-tags = {binary,first select,machine learning,second select,source code,source code-important,source code-vice important,web},
}

@Article{Grossman,
  author        = {Grossman, Dan},
  title         = {{Cyclone: A Type-Safe Dialect of C}},
  __markedentry = {[ccc:6]},
  file          = {:article\\Cyclone A safe dialect of C.pdf:PDF},
  groups        = {vice-important},
  isbn          = {1-880446-00-6},
  keywords      = {first select,second select,source code,source code-important,source code-vice important,stat,static analysi,static analysis,web},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Article{Goichi,
  author        = {Goichi, Nakamura and Kyoko, Makino and Ichiro, Murase},
  title         = {{2-4 Buffer-Overflow Detection in C Program}},
  pages         = {35--41},
  __markedentry = {[ccc:3]},
  file          = {:article\\Buffer-Overflow Detection in C Program by Static Detection.pdf:PDF},
  groups        = {imprortant},
  keywords      = {buffer{\_}overflow, first select, second select, source code, source code-important, source code-vice important, stat, static analysi, static analysis, vulnerability detection, web, rank3},
  mendeley-tags = {first select,second select,source code,source code-important,source code-vice important,web},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:source code\;0\;;
2 ExplicitGroup:imprortant\;0\;;
2 ExplicitGroup:vice-important\;0\;;
}
